{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef6e59c4-1cf7-47b8-845e-aab23351901f",
   "metadata": {},
   "source": [
    "# (Improved) Learning to Sample Ray Paths for Faster Ray Tracing\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/jeertmans/DiffeRT2d/blob/main/docs/source/notebooks/cost20120_helsinki_improved_model.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "In this notebook, we present an improved version of\n",
    "our Machine Learning model {cite}`learning-sample-ray-cost-2024`,\n",
    "with inspiration\n",
    "from the Generative Augented Flow Networks see {cite}`gaflownet`.\n",
    "\n",
    "Our model tries to learn how to sample valid ray paths\n",
    "to reduce the overall computational complexity of Ray Tracing (RT).\n",
    "\n",
    "For more details, please refer to the\n",
    "[Python notebook of the base model](./cost20120_helsinki_model.ipynb).\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In the base model, we observed that..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9311af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few importants imports to be able to run our code\n",
    "# 'type hint' related imports are only here for help documenting the code!\n",
    "\n",
    "try:\n",
    "    import differt2d  # noqa: F401\n",
    "except ImportError:\n",
    "    import sys  # noqa: F401\n",
    "\n",
    "    !{sys.executable} -m pip install git+https://github.com/jeertmans/DiffeRT2d.git\n",
    "\n",
    "from collections.abc import Iterator\n",
    "\n",
    "import equinox as eqx\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import optax\n",
    "from beartype import beartype as typechecker\n",
    "from jaxtyping import Array, Float, Int, PRNGKeyArray, jaxtyped\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "from differt2d.geometry import ImagePath, Point, Wall\n",
    "from differt2d.logic import is_true\n",
    "from differt2d.scene import Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fa0c3b-61dd-4da7-af37-584b51ebbc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(12345)  # 12345 is the 'random seed'\n",
    "key, key_example_scene = jax.random.split(key, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dfeb25-660d-4cf7-9675-7896234f9eeb",
   "metadata": {},
   "source": [
    "## Training data generation\n",
    "\n",
    "For this example, we limit ourselves to the study of specular reflection paths\n",
    "on straight walls. This is, **however**, not a limitation of our model.\n",
    "\n",
    "We generate data by applying random modifications on the very basic\n",
    "*square scene with obstacle*. The training data is simply a never ending\n",
    "iterator, which makes it very convenient of we want to increase the number\n",
    "of training steps.\n",
    "\n",
    "As every training sample is different, there is not real need to have both\n",
    "a training set and a test set. However, we will produce a validation set\n",
    "that will evaluate our model on a, hopefully representative, set of scenes.\n",
    "\n",
    "Also, the GFlowNet architecture has the advantage that we **do not** actually need\n",
    "the have a ground truth. Indeed, we simply need to have some *reward function*\n",
    "that evaluated some path candidate sampled by our model. Thus, this avoids\n",
    "us to enumerate all possible paths during training[^2].\n",
    "\n",
    "[^2]: As we will see in the [discussion](#discussion),\n",
    "    precomputing all possible paths during\n",
    "    training could help us skip scenes with no valid path, as it was observed\n",
    "    that it could improve the overall model's performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c60a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_samples(\n",
    "    min_ratio: float = 0.20,\n",
    "    max_ratio: float = 0.40,\n",
    "    min_num_walls: int = 4,\n",
    "    min_angle: float = -0.1 * jnp.pi,\n",
    "    max_angle: float = +0.1 * jnp.pi,\n",
    "    *,\n",
    "    key: PRNGKeyArray,\n",
    ") -> Iterator[Float[Array, \"2+num_walls*2 2\"]]:\n",
    "    \"\"\"\n",
    "    Returns a generator of random variants of :func:`Scene.square_scene_with_obstacle`.\n",
    "\n",
    "    The generation follows a three-steps process:\n",
    "\n",
    "    1. generate a ``square_scene_with_obstacle`` with a random scaling ratio;\n",
    "    2. sample a random number of walls from this scene;\n",
    "    3. and apply a random rotation around the scene's center for each wall.\n",
    "\n",
    "    :param min_ratio: The minimum scaling ratio of the inner square obstacle.\n",
    "    :param min_ratio: The maximum scaling ratio of the inner square obstacle.\n",
    "    :param min_num_walls: The minimum number of walls to sample (maximum is 8).\n",
    "    :param min_angle: The minimum rotation angle (random for each wall).\n",
    "    :param max_angle: The maximum rotation angle (random for each wall).\n",
    "    :param key: The random key to be used.\n",
    "    :return: An iterator over xys samples\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        key, key_ratio, key_tx_rx, key_num_walls, key_walls, key_angles = (\n",
    "            jax.random.split(key, 6)\n",
    "        )\n",
    "        # A random scaling is applied to the inner square\n",
    "        ratio = jax.random.uniform(key_ratio, minval=min_ratio, maxval=max_ratio)\n",
    "        # TX and RX are randomly sampled\n",
    "        points = jax.random.uniform(key_tx_rx, (2, 2))\n",
    "        # The walls are samples from the scene\n",
    "        scene = Scene.square_scene_with_obstacle(ratio=ratio)\n",
    "        center = scene.center()\n",
    "        indices = jnp.arange(len(scene.objects), dtype=jnp.int32)\n",
    "        # The number of walls is random\n",
    "        num_walls = jax.random.randint(\n",
    "            key_num_walls, (), minval=min_num_walls, maxval=len(scene.objects) + 1\n",
    "        )\n",
    "        # Walls are shuffled (to make sure deepset models\n",
    "        # is permutation invariant, but should not be needed)\n",
    "        wall_indices = jax.random.choice(\n",
    "            key_walls, indices, shape=(num_walls,), replace=False\n",
    "        )\n",
    "        # Each wall receives a random permutation around the center of the scene\n",
    "        angles = jax.random.uniform(\n",
    "            key_angles, shape=(num_walls,), minval=min_angle, maxval=max_angle\n",
    "        )\n",
    "        objects = [\n",
    "            scene.objects[wall_index].rotate(angle=angle, around=center)\n",
    "            for wall_index, angle in zip(wall_indices, angles)\n",
    "        ]\n",
    "\n",
    "        points = jnp.vstack([points, *[obj.xys for obj in objects]])\n",
    "\n",
    "        yield points\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def sample_2_scene(xys: Float[Array, \"2+num_walls*2 2\"]) -> Scene:\n",
    "    \"\"\"\n",
    "    Creates the scene corresponding to the given sample.\n",
    "\n",
    "    :param xys: The sample as returned by :func:`random_samples`.\n",
    "    :return: The corresponding scene.\n",
    "    \"\"\"\n",
    "    tx = Point(xy=xys[0, :])\n",
    "    rx = Point(xy=xys[1, :])\n",
    "\n",
    "    walls = xys[2:].reshape(-1, 2, 2)\n",
    "    walls = [Wall(xys=wall) for wall in walls]\n",
    "\n",
    "    return Scene(transmitters={\"tx\": tx}, receivers={\"rx\": rx}, objects=walls)\n",
    "\n",
    "\n",
    "samples = random_samples(key=key_example_scene)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6369c1-55bd-45ae-a5ef-16def56cd3f7",
   "metadata": {},
   "source": [
    "=(random-scene-example)\n",
    "### Example of random scene\n",
    "\n",
    "Below, we can see one of the random scenes generated by our function defined just before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eabdeb5-1f97-4745-b4db-bdb17205e7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell multiple times for different results!\n",
    "\n",
    "ax = plt.gca()\n",
    "scene = sample_2_scene(next(samples))\n",
    "scene.plot(ax)\n",
    "\n",
    "for _, _, path, _ in scene.all_valid_paths(order=order):\n",
    "    path.plot(ax)\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741db7a8-3530-450d-ac97-3dbf7eccfe24",
   "metadata": {},
   "source": [
    "### Training and validation samples\n",
    "\n",
    "Because our data generation produces a never-ending sequence of\n",
    "samples, each sample being unique, we can very well take the 100 first samples\n",
    "and use them as a validation set.\n",
    "\n",
    "Using 100 samples is a bit arbitrary, as it assumes that those 100\n",
    "samples can be representative of the distribution of all possible\n",
    "scenes. We will discuss that assumptions in the [discussion](#discussion)\n",
    "section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac336913-6a59-4eda-9ddc-621fc12b9a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, key_samples = jax.random.split(key, 2)\n",
    "\n",
    "# Let's filter out the cases with not valid paths,\n",
    "# because they are not interesting to learn from.\n",
    "\n",
    "num_val_samples = 100\n",
    "\n",
    "train_samples = random_samples(key=key_samples)\n",
    "\n",
    "val_samples = [next(train_samples) for i in range(num_val_samples)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ed2260-d750-4b06-a127-625ad1688489",
   "metadata": {},
   "source": [
    "## Reward function\n",
    "\n",
    "To indicate our model which path candidates should be sampled\n",
    "(and which paths should not), we define a *reward* function.\n",
    "\n",
    "The goal of the reward function is to give a high reward to valid paths,\n",
    "and and a low reward to invalid ones.\n",
    "\n",
    "The simplest reward possible is the following: valid path candidates\n",
    "receive a reward of 1, while invalid path candidates receive no reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec513edd-a2d1-475e-91b7-81430bf7ab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "@jaxtyped(typechecker=typechecker)\n",
    "def reward(\n",
    "    pred_path_candidate: Int[Array, \"order\"],\n",
    "    scene: Scene,\n",
    ") -> Float[Array, \" \"]:\n",
    "    \"\"\"\n",
    "    Rewards a predicted path candidate depending on if it\n",
    "    produces a valid path in the given scene.\n",
    "\n",
    "    :param pred_path_candidate: The predicted path candidate.\n",
    "    :param scene: The scene in which the path is traced.\n",
    "    :return: The (positive) reward.\n",
    "    \"\"\"\n",
    "    tx = scene.transmitters[\"tx\"]\n",
    "    rx = scene.receivers[\"rx\"]\n",
    "\n",
    "    # The following it a JIT-compatible variant of scene.get_interacting_objects\n",
    "    xys = jnp.stack(\n",
    "        [wall.xys for wall in scene.objects]\n",
    "    )  # Stack all walls into one array\n",
    "    interacting_walls = jnp.take(xys, pred_path_candidate, axis=0)\n",
    "    interacting_walls = [Wall(xys=wall) for wall in interacting_walls]\n",
    "\n",
    "    path = ImagePath.from_tx_objects_rx(tx, interacting_walls, rx)\n",
    "    valid = path.is_valid(scene.objects, pred_path_candidate, interacting_walls)\n",
    "\n",
    "    return valid.astype(float)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "@jaxtyped(typechecker=typechecker)\n",
    "def intermediate_reward(\n",
    "    intermediate_path_candidate: Int[Array, \"intermediate_order\"],\n",
    "    scene: Scene,\n",
    "    *,\n",
    "    key: PRNGKeyArray,\n",
    ") -> Float[Array, \" \"]:\n",
    "    \"\"\"\n",
    "    Rewards an intermediate path candidate depending on if it could\n",
    "    produce a valid path in the given scene.\n",
    "\n",
    "    :param intermediate_path_candidate: The intermediate path candidate.\n",
    "    :param scene: The scene in which the path is traced.\n",
    "    :return: The (positive) reward.\n",
    "    \"\"\"\n",
    "    assert intermediate_path_candidate.size > 0\n",
    "    last_wall_index = intermediate_path_candidate[-1]\n",
    "    last_wall = scene.get_object(last_wall_index)\n",
    "\n",
    "    scene = scene.with_receivers(rx=last_wall.sample(key=key))\n",
    "\n",
    "    return reward(intermediate_path_candidate[:-1], scene)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac4d34c-7402-48d8-a797-296911d4328e",
   "metadata": {},
   "source": [
    "Let us take a look at the rewards of the different path candidates from the above scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e61089-be16-4561-bb5d-515a57a36976",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "scene.plot(ax)\n",
    "\n",
    "for _, _, valid, path, path_candidate in scene.all_paths(order=order):\n",
    "    if is_true(valid):\n",
    "        path.plot(ax)\n",
    "        s = \"valid  :\"\n",
    "    else:\n",
    "        s = \"invalid:\"\n",
    "\n",
    "    p = path_candidate.tolist()\n",
    "    r = reward(path_candidate, scene)\n",
    "\n",
    "    print(f\"{s} path_candidate = {p} has a reward of {r}\")\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f48cbad-fbad-456a-aff0-8ed66c850d1b",
   "metadata": {},
   "source": [
    "## Model definition\n",
    "\n",
    "Our model follows the architecture of GFlowNet models: the goal is to **learn how sample path candidates**\n",
    "(here, the final state of the flowchart) such that their sampling rate is proportional to their corresponding\n",
    "reward.\n",
    "\n",
    "A path candidate is simply a list of wall indices, e.g., `[A, C]`[^3]. A path candidate under\n",
    "construction (i.e., not yet completed), is represented with `X` for undecided states.\n",
    "\n",
    "[^3]: Numeric indices are replaced here with letters, to make it simpler. In practice, walls\n",
    "    are identified based on a zero-based array indexing.\n",
    "\n",
    "E.g., `path_candidate = [A, X]` indicates a path with 2 interactions, where the first\n",
    "is already defined (i.e., wall `A`).\n",
    "\n",
    "For each path candidate, either incomplete or complete, there is a unique state $s$ representing it. In the code, states\n",
    "are obtained by encoding the corresponding path candidate using one-hot encoding.\n",
    "\n",
    "E.g., the complete `path_candidate = [A, C]` is represented by the following state\n",
    "(assuming 3 objects in the scene):\n",
    "\n",
    "```python\n",
    "state = [\n",
    "  [1, 0],  # Wall A\n",
    "  [0, 0],  # Wall B\n",
    "  [0, 1],  # Wall C\n",
    "]\n",
    "```\n",
    "\n",
    "While the incomplete `path_candidate = [A, X]` is represented by:\n",
    "\n",
    "```python\n",
    "state = [\n",
    "  [1, 0],  # Wall A\n",
    "  [0, 0],  # Wall B\n",
    "  [0, 0],  # Wall C\n",
    "]\n",
    "```\n",
    "\n",
    "The last column being all zeros refers to the `X`.\n",
    "\n",
    "Below, the diagram of all possible states is shown. As interacting with the same\n",
    "object twice in a row is **physically unsound**, this state is **unreachable** (dotted lines).\n",
    "To account for that in the model, the flow is stopped to prevent reaching those states.\n",
    "\n",
    "```{mermaid}\n",
    ":align: center\n",
    ":caption: Flowchart of all possible states for a 2-order path candidates in a scene with 3 walls.\n",
    "\n",
    "flowchart TD\n",
    "    ?(??) -->|\"F(??, A?)\"| A(A?)\n",
    "    ? -->|\"F(??, A?)\"| B(B?)\n",
    "    ? -->|\"F(??, A?)\"| C(C?)\n",
    "\n",
    "    A -.-x|\"F(A?, AA)\"| AA(AA)\n",
    "    A -->|\"F(A?, AB)\"| AB(AB)\n",
    "    A -->|\"F(A?, AC)\"| AC(AC)\n",
    "\n",
    "    B -->|\"F(B?, BA)\"| BA(BA)\n",
    "    B -.-x|\"F(B?, BB)\"| BB(BB)\n",
    "    B -->|\"F(B?, BC)\"| BC(BC)\n",
    "\n",
    "    C -->|\"F(C?, CA)\"| CA(CA)\n",
    "    C -->|\"F(C?, CB)\"| CB(CB)\n",
    "    C -.-x|\"F(C?, CC)\"| CC(CC)\n",
    "```\n",
    "\n",
    "The construction of any path candidate start at the `??` state.\n",
    "Then, the next state is chosen randomly, accordingly to the flow model,\n",
    "see next the [loss function definition](#loss-function-definition) for more details.\n",
    "For second order path candidates, this step is **repeated twice**.\n",
    "\n",
    "The next flowchart indicate the construction of `path_candidate = [A, X]`.\n",
    "\n",
    "```{mermaid}\n",
    ":align: center\n",
    ":caption: Flowchart of with edge leading to the construction of `[A, X]` highlighted.\n",
    "\n",
    "flowchart TD\n",
    "    ?(??) -->|\"F(??, A?)\"| A(A?)\n",
    "    ? -->|\"F(??, A?)\"| B(B?)\n",
    "    ? -->|\"F(??, A?)\"| C(C?)\n",
    "\n",
    "    A -.-x|\"F(A?, AA)\"| AA(AA)\n",
    "    A -->|\"F(A?, AB)\"| AB(AB)\n",
    "    A -->|\"F(A?, AC)\"| AC(AC)\n",
    "\n",
    "    B -->|\"F(B?, BA)\"| BA(BA)\n",
    "    B -.-x|\"F(B?, BB)\"| BB(BB)\n",
    "    B -->|\"F(B?, BC)\"| BC(BC)\n",
    "\n",
    "    C -->|\"F(C?, CA)\"| CA(CA)\n",
    "    C -->|\"F(C?, CB)\"| CB(CB)\n",
    "    C -.-x|\"F(C?, CC)\"| CC(CC)\n",
    "    \n",
    "    linkStyle 0 stroke:#ff3,stroke-width:4px,background-color:lime;\n",
    "```\n",
    "\n",
    "Finally, the complete path candidate, here `[A, C]` is reached after a second call to our model.\n",
    "\n",
    "```{mermaid}\n",
    ":align: center\n",
    ":caption: Flowchart of with edges leading to the construction of `[A, C]` highlighted.\n",
    "\n",
    "flowchart TD\n",
    "    ?(??) -->|\"F(??, A?)\"| A(A?)\n",
    "    ? -->|\"F(??, A?)\"| B(B?)\n",
    "    ? -->|\"F(??, A?)\"| C(C?)\n",
    "\n",
    "    A -.-x|\"F(A?, AA)\"| AA(AA)\n",
    "    A -->|\"F(A?, AB)\"| AB(AB)\n",
    "    A -->|\"F(A?, AC)\"| AC(AC)\n",
    "\n",
    "    B -->|\"F(B?, BA)\"| BA(BA)\n",
    "    B -.-x|\"F(B?, BB)\"| BB(BB)\n",
    "    B -->|\"F(B?, BC)\"| BC(BC)\n",
    "\n",
    "    C -->|\"F(C?, CA)\"| CA(CA)\n",
    "    C -->|\"F(C?, CB)\"| CB(CB)\n",
    "    C -.-x|\"F(C?, CC)\"| CC(CC)\n",
    "    \n",
    "    linkStyle 0 stroke:#ff3,stroke-width:4px,background-color:lime;\n",
    "    linkStyle 5 stroke:#ff3,stroke-width:4px,background-color:lime;\n",
    "```\n",
    "\n",
    "We therefore define two classes: `FlowModel`, that will learn the flow relationships between states,\n",
    "and `Model`, that will use a trained `FlowModel` to generate a complete path candidate.\n",
    "\n",
    "When combined, the process of generating, or sampling, path candidates can be\n",
    "represented as in the following graph.\n",
    "\n",
    "```{mermaid}\n",
    ":align: center\n",
    ":caption: Graph of the (simplified) sampling process, and other usual steps.\n",
    "\n",
    "graph LR\n",
    "    GE[[Geometry]]\n",
    "    O[[order]]\n",
    "    FM((Flow<br>model))\n",
    "    PT(Path tracing)\n",
    "    PP(Path post-processing)\n",
    "    EM(EM Fields)\n",
    "\n",
    "    subgraph Model\n",
    "        FM  \n",
    "    end\n",
    "\n",
    "    FM--> |order times| FM\n",
    "    GE --> Model\n",
    "    O --> Model\n",
    "    Model -->|\"Path candidate\"| PT\n",
    "    PT -->|\"Ray path\"| PP\n",
    "    PP -->|\"Valid ray path\"| EM\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c985f39b-501f-4c4a-abdf-474c1568ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowModel(eqx.Module):\n",
    "    \"\"\"The flow model that returns flows between two states.\"\"\"\n",
    "\n",
    "    # Layers\n",
    "    wall_2_embeddings: eqx.nn.MLP\n",
    "    \"\"\"MLP that is applied to each wall in parallel and\n",
    "    returns the corresponding embeddings.\"\"\"\n",
    "    embeddings_2_flow: eqx.nn.MLP\n",
    "    \"\"\"MLP that maps each possible choice to some positive flow.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        # Hyperparameters\n",
    "        num_embeddings: int = 100,\n",
    "        *,\n",
    "        key: PRNGKeyArray,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Constructs a GFlowNet model.\n",
    "\n",
    "        :param num_embeddings: The size of the vector that will represent each wall.\n",
    "        :param key: The random key to be used.\n",
    "        \"\"\"\n",
    "        key1, key2 = jax.random.split(key, 2)\n",
    "\n",
    "        # Layers\n",
    "        self.wall_2_embeddings = eqx.nn.MLP(\n",
    "            in_size=4,\n",
    "            out_size=num_embeddings,\n",
    "            width_size=500,\n",
    "            depth=3,\n",
    "            key=key1,\n",
    "        )\n",
    "        self.embeddings_2_flow = eqx.nn.MLP(\n",
    "            in_size=4\n",
    "            + 2 * num_embeddings\n",
    "            + 4,  # [tx_rx, state_embeddings, scene_embeddings, wall[i]]\n",
    "            out_size=\"scalar\",\n",
    "            width_size=500,\n",
    "            depth=3,\n",
    "            final_activation=jnp.exp,  # Positive flow only\n",
    "            key=key2,\n",
    "        )\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    @jaxtyped(typechecker=typechecker)\n",
    "    def __call__(\n",
    "        self,\n",
    "        state: Float[Array, \"num_walls order\"],\n",
    "        wall_index: Int[Array, \" \"],\n",
    "        xys: Float[Array, \"2+num_walls*2 2\"],\n",
    "    ) -> Float[Array, \"num_walls\"]:\n",
    "        \"\"\"\n",
    "        Calls this model in order to generate a new flow from a given state,\n",
    "        the last selected wall index, and some input scene.\n",
    "\n",
    "        :param state: The current state, a one-hot encoding of the path candidate\n",
    "            in construction. Only one element per column can be non-zero.\n",
    "        :param wall_index: The index of the last wall that was selected. A negative index\n",
    "            indicates that no wall was previously selected.\n",
    "        :param xys: The array of xy-coordinates, as returned by\n",
    "            :func:`random_samples`.\n",
    "        :return: The array of flows, one per wall in the scene.\n",
    "        \"\"\"\n",
    "        assert (\n",
    "            xys.shape[0] >= 4\n",
    "        ), \"Scene must at least have two points, tx and rx, and one wall!\"\n",
    "\n",
    "        num_walls, order = state.shape\n",
    "\n",
    "        # Data normalization\n",
    "        eps = 1e-5\n",
    "        mean = jnp.mean(xys, axis=0, keepdims=True)\n",
    "        std = jnp.std(xys, axis=0, keepdims=True)\n",
    "\n",
    "        xys = (xys - mean) / (std + eps)\n",
    "\n",
    "        tx_rx = xys[:2, :].reshape(4)\n",
    "        walls = xys[2:, :].reshape(num_walls, 4)\n",
    "\n",
    "        # [num_walls 4]\n",
    "        # note: this input we be the same for every wall\n",
    "        tx_rx = jnp.tile(tx_rx, (num_walls, 1))\n",
    "\n",
    "        # [num_walls num_embeddings]\n",
    "        # note: each wall is mapped to a vector of embeddings\n",
    "        walls_embeddings = jax.vmap(self.wall_2_embeddings)(walls)\n",
    "\n",
    "        # [num_embeddings]\n",
    "        # note: the scene is the sum of all embeddings\n",
    "        scene_embeddings = jnp.sum(walls_embeddings, axis=0)\n",
    "\n",
    "        # [num_walls num_embeddings]\n",
    "        # note: this input we be the same for every wall\n",
    "        scene_embeddings = jnp.tile(scene_embeddings, (num_walls, 1))\n",
    "\n",
    "        # [order]\n",
    "        # note: fill_value=num_walls is important as we need to generate 'out of bounds'\n",
    "        #       indices for missing values (only current_order <= order are non zero)\n",
    "        wall_indices, _ = jnp.nonzero(state, size=order, fill_value=num_walls)\n",
    "\n",
    "        # [order num_embeddings]\n",
    "        # note: we tell JAX to replace 'out of bounds' indices with zeros,\n",
    "        #       as this will have no impact on the sum (see next step)\n",
    "        state_embeddings = jnp.take(\n",
    "            walls_embeddings, wall_indices, axis=0, fill_value=0\n",
    "        )\n",
    "\n",
    "        # [num_embeddings]\n",
    "        # note: this contains information about the walls we already visited,\n",
    "        #       as a sum of corresponding embeddings (one wall can appear multiple times)\n",
    "        state_embeddings = jnp.sum(state_embeddings, axis=0)\n",
    "\n",
    "        # [num_walls num_embeddings]\n",
    "        # note: this input we be the same for every wall\n",
    "        state_embeddings = jnp.tile(state_embeddings, (num_walls, 1))\n",
    "\n",
    "        # [num_walls]\n",
    "        # note: the input (per wall) looks as follows\n",
    "        #       # [tx_rx, state_embeddings, scene_embeddings, wall[i]]\n",
    "        flow = jax.vmap(self.embeddings_2_flow)(\n",
    "            jnp.hstack((tx_rx, state_embeddings, scene_embeddings, walls))\n",
    "        )\n",
    "\n",
    "        # Set flow[wall_index] to zero to prevent consecutive duplicate indices\n",
    "        # A flow of zero means that there is a zero probability to pick\n",
    "        # walls[wall_index] for the next state.\n",
    "        flow = flow.at[wall_index].set(0.0)  # out of bounds indices are ignored\n",
    "\n",
    "        return flow\n",
    "\n",
    "\n",
    "class Model(eqx.Module):\n",
    "    \"\"\"The generative model that samples a path candidate from flows.\"\"\"\n",
    "\n",
    "    flow: FlowModel\n",
    "    \"\"\"The learnable flow model.\"\"\"\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def __call__(\n",
    "        self,\n",
    "        xys: Float[Array, \"2+num_walls*2 2\"],\n",
    "        *,\n",
    "        order: int,\n",
    "        key: PRNGKeyArray,\n",
    "    ) -> Int[Array, \"{order}\"]:\n",
    "        \"\"\"\n",
    "        Calls this model to generate a path candidate of the given order.\n",
    "\n",
    "        :param xys: The array of xy-coordinates, as returned by\n",
    "            :func:`random_samples`.\n",
    "        :param order: The order of the path candidate.\n",
    "        :param key: The random key to be used.\n",
    "        :return: A path candidate.\n",
    "        \"\"\"\n",
    "        # See loss function for detailed comments\n",
    "        num_walls = (xys.shape[0] - 2) // 2\n",
    "\n",
    "        ScanR = Int[Array, \" \"]\n",
    "        ScanC = tuple[\n",
    "            Float[Array, \" num_walls\"],\n",
    "            Float[Array, \"num_walls order\"],\n",
    "        ]\n",
    "\n",
    "        @jaxtyped(typechecker=typechecker)\n",
    "        def scan_fn(\n",
    "            carry: ScanC, key_and_current_order: tuple[PRNGKeyArray, Int[Array, \" \"]]\n",
    "        ) -> tuple[ScanC, ScanR]:\n",
    "            parent_edge_flow_prediction, state = carry\n",
    "            key, current_order = key_and_current_order\n",
    "\n",
    "            p = parent_edge_flow_prediction / jnp.sum(parent_edge_flow_prediction)\n",
    "\n",
    "            wall_index = jax.random.categorical(key=key, logits=jnp.log(p))\n",
    "\n",
    "            state = state.at[wall_index, current_order].set(1.0)\n",
    "\n",
    "            edge_flow_prediction = self.flow(state, wall_index, xys)\n",
    "\n",
    "            return (edge_flow_prediction, state), wall_index\n",
    "\n",
    "        wall_index = jnp.array(num_walls)\n",
    "        state = jnp.zeros((num_walls, order))\n",
    "        parent_edge_flow_prediction = self.flow(state, wall_index, xys)\n",
    "        init = parent_edge_flow_prediction, state\n",
    "        _, pred_path_candidate = jax.lax.scan(\n",
    "            scan_fn,\n",
    "            init,\n",
    "            xs=(jax.random.split(key, order), jnp.arange(order)),\n",
    "        )\n",
    "\n",
    "        return pred_path_candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7470ffd2-f9c3-4e68-a535-c3848af1a60f",
   "metadata": {},
   "source": [
    "## Loss function definition\n",
    "\n",
    "A central property of GFlowNet models that, after successful training, the model should sample terminal states, i.e.,\n",
    "complete path candidates, with a probability $p$, that is proportional to their corresponding reward, $R$.\n",
    "\n",
    "In other words,\n",
    "\n",
    "```{math}\n",
    "p(\\mathcal{P}) \\propto R(\\mathcal{P}),\n",
    "```\n",
    "\n",
    "where $\\mathcal{P}$ is one possible path candidate, \n",
    "\n",
    "To reach this property, the model must have the following properties:\n",
    "\n",
    "1. each edge must be assigned a positive flow, $F(s,s') > 0$, where $s$ is the parent state and $s'$ is the child state;\n",
    "2. the flow consistency must be ensured:\n",
    "   ```{math}\n",
    "   :label: flow_consistency\n",
    "   \\forall s', F(s,s') = R(s') + \\sum_{s''}F(s',s''),\n",
    "   ```\n",
    "   that is, the sum of output flows, $F(s',s'')$, must be equal to the input flow, $F(s,s')$, minus the reward;\n",
    "4. and\n",
    "   ```{math}\n",
    "   p(s'|s) = \\frac{F(s,s')}{\\sum_{s''}F(s,s'')},\n",
    "   ```\n",
    "   that is, the probability of choosing state $s'$ from state $s$.\n",
    "\n",
    "Note that all states, except the terminal states, have a zero reward.\n",
    "\n",
    "For training a Deep Sets model, we minimize the GFlowNets loss function, which rewrites [](#flow_consistency) as a mean squared error:\n",
    "\n",
    "```{math}\n",
    "L(s') = \\left(F(s,s') - R(s') - \\sum_{s''}F(s',s'') \\right)^2.\n",
    "```\n",
    "\n",
    "The following cell contains a lot of boilerplate code to generate multiple path\n",
    "candidates for a given scene, and optionally plot the output in a nice way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be7b365-8559-4413-8485-a6126cebee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jaxtyped(typechecker=None)\n",
    "def loss(\n",
    "    model: FlowModel,\n",
    "    xys: Float[Array, \"2+num_walls*2 2\"],\n",
    "    batch_size: int = 10,\n",
    "    plot: bool = False,\n",
    "    *,\n",
    "    order: int,\n",
    "    key: PRNGKeyArray,\n",
    ") -> Float[Array, \" \"]:\n",
    "    \"\"\"\n",
    "    Compute the loss of the model on a specific input scene.\n",
    "\n",
    "    The loss is accumulated over the generation of 'batch_size' path candidates.\n",
    "    \"\"\"\n",
    "    num_walls = (xys.shape[0] - 2) // 2\n",
    "    scene = sample_2_scene(xys)\n",
    "\n",
    "    BatchC = Float[Array, \" \"]\n",
    "    BatchR = Int[Array, \" order\"]\n",
    "\n",
    "    @jaxtyped(typechecker=typechecker)\n",
    "    def batch_fn(batch_loss: BatchC, key: PRNGKeyArray) -> tuple[BatchC, BatchR]:\n",
    "        flow_mismatch = jnp.array(0.0)\n",
    "        wall_index = jnp.array(\n",
    "            num_walls\n",
    "        )  # We didn't select any wall yet: out of bounds index\n",
    "        state = jnp.zeros(\n",
    "            (num_walls, order)\n",
    "        )  # Same, but represented in one-hot encoding\n",
    "        parent_edge_flow_prediction = model(\n",
    "            state, wall_index, xys\n",
    "        )  # Initial state's flow\n",
    "        pred_path_candidate = jnp.full(order, num_walls, dtype=int)\n",
    "\n",
    "        for current_order, key_loop in enumerate(jax.random.split(key, order)):\n",
    "            # Turn positive flow into normalized probability in [0, 1]\n",
    "            p = parent_edge_flow_prediction / jnp.sum(parent_edge_flow_prediction)\n",
    "\n",
    "            key_index, key_intermediate_reward = jax.random.split(key_loop, 2)\n",
    "\n",
    "            wall_index = jax.random.categorical(\n",
    "                key=key_index, logits=jnp.log(p)\n",
    "            )  # The wall to choose\n",
    "\n",
    "            # Indicate we have chosen walls[wall_index] as a candidate at 'current_order'\n",
    "            state = state.at[wall_index, current_order].set(1.0)\n",
    "            pred_path_candidate = pred_path_candidate.at[current_order].set(wall_index)\n",
    "\n",
    "            edge_flow_prediction = model(state, wall_index, xys)\n",
    "\n",
    "            if current_order == order - 1:  # Check whether we reached final state\n",
    "                r = reward(pred_path_candidate, scene)\n",
    "                flow_mismatch += (\n",
    "                    (  # Reached last state so (next) edge_flow_prediction is ignored\n",
    "                        parent_edge_flow_prediction[\n",
    "                            wall_index\n",
    "                        ]  # Each state s' has only one possible parent state s\n",
    "                        - r\n",
    "                    )\n",
    "                    ** 2\n",
    "                )\n",
    "            else:\n",
    "                ir = intermediate_reward(\n",
    "                    pred_path_candidate[: current_order + 1],\n",
    "                    scene,\n",
    "                    key=key_intermediate_reward,\n",
    "                )\n",
    "                flow_mismatch += (  # Didn't reach last state so no reward\n",
    "                    parent_edge_flow_prediction[\n",
    "                        wall_index\n",
    "                    ]  # Each state s' has only one possible parent state s\n",
    "                    - jnp.sum(edge_flow_prediction)\n",
    "                    - ir\n",
    "                ) ** 2\n",
    "\n",
    "        return batch_loss + flow_mismatch, pred_path_candidate\n",
    "\n",
    "    batch_loss = jnp.array(0.0)\n",
    "    batch_loss, pred_path_candidates = jax.lax.scan(\n",
    "        batch_fn, batch_loss, xs=jax.random.split(key, batch_size)\n",
    "    )\n",
    "\n",
    "    if plot:  # Let's see the prediction vs ground truth\n",
    "        ax = plt.gca()\n",
    "        scene.plot(ax)\n",
    "        ax.set_xlim(-0.1, 1.1)\n",
    "        ax.set_ylim(-0.1, 1.1)\n",
    "        tx = scene.transmitters[\"tx\"]\n",
    "        rx = scene.receivers[\"rx\"]\n",
    "\n",
    "        gt = None\n",
    "        for _, _, path, _ in scene.all_valid_paths(order=order):\n",
    "            (gt,) = path.plot(ax, color=\"orange\")\n",
    "\n",
    "        if gt is not None:\n",
    "            gt.set_label(\"Ground Truth\")\n",
    "\n",
    "        n_unique = 0\n",
    "        pr = None\n",
    "        for pred_path_candidate in jnp.unique(pred_path_candidates, axis=0):\n",
    "            n_unique += 1\n",
    "            objects = [scene.objects[i] for i in pred_path_candidate]\n",
    "            (pr,) = ImagePath.from_tx_objects_rx(tx, objects, rx).plot(\n",
    "                ax, linestyle=\"--\", alpha=0.5, color=\"red\"\n",
    "            )\n",
    "\n",
    "        if pr is not None:\n",
    "            pr.set_label(\"Prediction\")\n",
    "\n",
    "        ax.set_title(\n",
    "            f\"Generated {batch_size} path cand. (of which {n_unique} are unique)\"\n",
    "        )\n",
    "        ax.set_xlabel(\"x coordinate\")\n",
    "        ax.set_ylabel(\"y coordinate\")\n",
    "        ax.legend()\n",
    "        plt.show()\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651b14d9-57cb-48e5-a438-c9e0204e06e5",
   "metadata": {},
   "source": [
    "### Evaluating the loss on an untrained model\n",
    "\n",
    "The following code shows how to initialize the model and\n",
    "how the loss function works. The order of paths must be specified\n",
    "at this will tell the loss function how many times the flow model\n",
    "should be called.\n",
    "\n",
    "To change the order of the generated path candidates,\n",
    "you just need to change the value of the `order=K` keyword-only argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf67f8a-b55a-4449-bdce-6a1fd6bf25fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, key_model = jax.random.split(key, 2)\n",
    "untrained_model = FlowModel(key=key_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7cb03a-b637-4fc5-bd98-129c48844f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell multiple times for different results!\n",
    "\n",
    "key, key_loss_untrained = jax.random.split(key, 2)\n",
    "loss(\n",
    "    untrained_model, next(train_samples), plot=True, order=1, key=key_loss_untrained\n",
    ")  # Untrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737b698a-6b75-4d5e-9f5c-e640efedb8d8",
   "metadata": {},
   "source": [
    "## Training phase\n",
    "\n",
    "In the proposed architecture, only the `FlowModel` needs to be trained.\n",
    "\n",
    "As a result, we defined a loss function directly deals with this model,\n",
    "and not with the `Model` class, and the learning procedure looks a bit\n",
    "like in the graph below.\n",
    "\n",
    "```{mermaid}\n",
    ":align: center\n",
    ":caption: Graph of the (simplified) learning process.\n",
    "\n",
    "graph LR\n",
    "    GE[[Geometry]]\n",
    "    PC((Flow<br>model))\n",
    "    R(Reward)\n",
    "    G(Gradients)\n",
    "\n",
    "    subgraph Loss\n",
    "        PC\n",
    "        R\n",
    "    end\n",
    "\n",
    "    PC --> |order times| PC\n",
    "    GE --> PC\n",
    "    PC -->|\"Path candidate\"| R\n",
    "    R --> |Loss| G\n",
    "    G -->|Update| PC\n",
    "```\n",
    "\n",
    "The training function is very simple, as it the complex part\n",
    "of performing the gradients update is done by {mod}`optax`.\n",
    "We decide to use one of the most popular model, Adam {cite}`adam`,\n",
    "but one could think of other optimizers (or meta-parameters)\n",
    "that may be best suited to this problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b8cc6c-23f7-4317-982f-f225efb9de82",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = optax.adam(learning_rate=3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930a3ef7-345b-4e47-993e-64944701a597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: FlowModel,\n",
    "    train_samples: Iterator[Float[Array, \"2+num_walls*2 2\"]],\n",
    "    val_samples: list[Float[Array, \"2+num_walls*2 2\"]],\n",
    "    optim: optax.GradientTransformation,\n",
    "    steps: int = 100_000,\n",
    "    print_every: int = 100,\n",
    "    *,\n",
    "    order: int,\n",
    "    key: PRNGKeyArray,\n",
    ") -> tuple[\n",
    "    FlowModel,\n",
    "    Float[Array, \"{steps}//{print_every}\"],\n",
    "    Float[Array, \"{steps}//{print_every}\"],\n",
    "    Float[Array, \"{steps}//{print_every}\"],\n",
    "]:\n",
    "    \"\"\"\n",
    "    Trains a flow model on a sequence of training samples and returns the averaged loss over validation samples.\n",
    "\n",
    "    :param model: The model to train.\n",
    "    :param train_samples: The training samples.\n",
    "    :param val_samples: The validation samples.\n",
    "    :param optim: The optimizer to use.\n",
    "    :param steps: The number of optimization steps.\n",
    "    :param print_every: The frequency at which the average loss is computed.\n",
    "    :param order: The order of the paths to be trained on.\n",
    "    :param key: The random key to be used.\n",
    "    :return: The trained model, the steps,\n",
    "        the train losses and the validation losses.\n",
    "    \"\"\"\n",
    "    opt_state = optim.init(eqx.filter(model, eqx.is_array))\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def make_step(\n",
    "        model: FlowModel,\n",
    "        opt_state: optax.OptState,\n",
    "        xys: Float[Array, \"2+num_walls*2 2\"],\n",
    "        *,\n",
    "        order: int,\n",
    "        key: PRNGKeyArray,\n",
    "    ):\n",
    "        loss_value, grads = eqx.filter_value_and_grad(loss)(\n",
    "            model, xys, order=order, key=key\n",
    "        )\n",
    "        updates, opt_state = optim.update(grads, opt_state, model)\n",
    "        model = eqx.apply_updates(model, updates)\n",
    "        return model, opt_state, loss_value\n",
    "\n",
    "    loss_steps = []\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    jitted_loss = eqx.filter_jit(loss)\n",
    "\n",
    "    with trange(steps, desc=\"\", unit=\" steps\", leave=True) as bar:\n",
    "        for (\n",
    "            step,\n",
    "            xys_train,\n",
    "        ) in zip(bar, train_samples):\n",
    "            key, key_step = jax.random.split(key, 2)\n",
    "\n",
    "            model, opt_state, train_loss = make_step(\n",
    "                model, opt_state, xys_train, order=order, key=key_step\n",
    "            )\n",
    "\n",
    "            if (step % print_every) == 0 or (step == steps - 1):\n",
    "                # Only update the training 'bar' every few steps\n",
    "                val_loss = 0.0\n",
    "                for xys_val in val_samples:\n",
    "                    key, key_val = jax.random.split(key, 2)\n",
    "                    val_loss += jitted_loss(model, xys_val, order=order, key=key_val)\n",
    "\n",
    "                val_loss /= len(val_samples)\n",
    "\n",
    "                loss_steps.append(step)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "\n",
    "                bar.set_description(\n",
    "                    f\"train_loss = {float(train_loss):.1f}, \"\n",
    "                    f\"val_loss = {float(val_loss):.1f}\"\n",
    "                )\n",
    "\n",
    "    return model, jnp.array(loss_steps), jnp.array(train_losses), jnp.array(val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c8c647-d73c-4b8b-95ef-156aed564610",
   "metadata": {},
   "source": [
    "### First order paths\n",
    "\n",
    "Below, we show the training process for learning how to sample first-order\n",
    "path candidates. As you can see from the plot of the loss function,\n",
    "the learning is not excellent, but we can observe that the model\n",
    "often returns valid path candidates, and that we don't just have\n",
    "`batch_size=10` random path candidates that are all different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c04eb13-9336-49d5-aecb-8588b265f13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, key_train = jax.random.split(key, 2)\n",
    "\n",
    "trained_model_order_1, order_1_steps, order_1_train_losses, order_1_val_losses = train(\n",
    "    untrained_model, train_samples, val_samples, optim, order=1, key=key_train\n",
    ")\n",
    "\n",
    "plt.semilogy(order_1_steps, order_1_train_losses, label=\"Train\")\n",
    "plt.semilogy(order_1_steps, order_1_val_losses, \"--\", label=\"Validation\")\n",
    "plt.title(\"Order 1\")\n",
    "plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d50bd34-18d6-40d8-bf15-e5ebb8be286c",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, key_loss_trained = jax.random.split(key, 2)\n",
    "\n",
    "loss(\n",
    "    trained_model_order_1, next(train_samples), plot=True, order=1, key=key_loss_trained\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db49c67c-c136-4738-b0bf-d9a1be767088",
   "metadata": {},
   "source": [
    "### Second order paths\n",
    "\n",
    "As our model does not directly depend on the `order` variable, we\n",
    "can very easily train it on second-order path candidates instead!\n",
    "\n",
    "In opposition to the first-order model, the results are far from being\n",
    "good, and the learning procedure seems to first reach a local minimum,\n",
    "and then increases to a plateau.\n",
    "Actually, even though the loss curve may look better, the predicted\n",
    "path candidates seems be invalid most of the time, which indicates\n",
    "that their is a failure in the learning process.\n",
    "\n",
    "Moreover, in some cases, e.g., when the learning rate is too large,\n",
    "we observe a *collapse mode* after some steps, where the model just\n",
    "converge to $F(s,s')=0$, for all states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ecfc03-a8a9-4265-a440-5edf7b25bdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, key_train = jax.random.split(key, 2)\n",
    "\n",
    "trained_model_order_2, order_2_steps, order_2_train_losses, order_2_val_losses = train(\n",
    "    untrained_model, train_samples, val_samples, optim, order=2, key=key_train\n",
    ")\n",
    "\n",
    "plt.semilogy(order_2_steps, order_2_train_losses, label=\"Train\")\n",
    "plt.semilogy(order_2_steps, order_2_val_losses, \"--\", label=\"Validation\")\n",
    "plt.title(\"Order 2\")\n",
    "plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef52320-0e1d-4463-8eb4-737ca97e3bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell multiple times for different results!\n",
    "key, key_loss_trained = jax.random.split(key, 2)\n",
    "\n",
    "loss(\n",
    "    trained_model_order_2, next(train_samples), plot=True, order=2, key=key_loss_trained\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d297052-23b9-43fa-a837-c4deca8fe3da",
   "metadata": {},
   "source": [
    "Alternatively, we could use the `trained_model_order_1` to generate\n",
    "second-order path candidates, hoping that it generalizes well\n",
    "on higher orders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe511be-0255-42b6-ab64-7f8c604699fe",
   "metadata": {},
   "source": [
    "## Inference phase\n",
    "\n",
    "Once the model has been trained, we can instantiate a complete Machine Learning\n",
    "model to sample path candidates. In itself, the `Model` class is just a plan\n",
    "wrapper around the trained `FlowModel` instance, that will call\n",
    "it repeatedly to generate path candidates of a given size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b806ea50-1a7f-4f79-87a1-8934baeed9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    flow=eqx.nn.inference_mode(\n",
    "        trained_model_order_2\n",
    "    )  # Here, this is a no-op (just copies the model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ef95aa-37cc-48a4-b098-33a3c202c082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell multiple times for different results!\n",
    "\n",
    "key, key_inference = jax.random.split(key, 2)\n",
    "\n",
    "model(next(train_samples), order=2, key=key_inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f0fa52-4b4d-44a5-8242-4441b01aded8",
   "metadata": {},
   "source": [
    "=(discussion)\n",
    "## Discussion\n",
    "\n",
    "In complement to what is discussed in our paper, we highlight the following \n",
    "future prospects:\n",
    "- removing from the training data the scenes that **do not contain any valid path**:\n",
    "  they are not actually very interesting for our problem, and may have a detrimental impact on the\n",
    "  learning process as the model will not receive any reward;\n",
    "- to enhance generalization, we also could think of accumulating the loss on several scenes, rather than one scene at a time;\n",
    "- and investigate a solution that aims to mitigate to impact of sparse reward functions, as in our case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc66ffb9-5d90-4094-a32c-9e329b70c195",
   "metadata": {},
   "source": [
    "## Appendix - Training on curated scenes\n",
    "\n",
    "As suggested in the [discussion](#discussion), we show how the training\n",
    "on a curated training dataset, i.e., with some scenes removed,\n",
    "can help improving the learning process.\n",
    "\n",
    "Here, the `filter_xys` function just returns `True` if the scene\n",
    "will at least contain one valid ray path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af102125-5fa4-485b-af4a-a63134d1e37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_xys(xys: Float[Array, \"2+num_walls*2 2\"]) -> bool:\n",
    "    \"\"\"\n",
    "    Returns True if the scene contains at least one valid path.\n",
    "\n",
    "    :param xys: The input scene.\n",
    "    :return: True if the scene should be kept.\n",
    "    \"\"\"\n",
    "    scene = sample_2_scene(xys)\n",
    "\n",
    "    for _ in scene.all_valid_paths(order=order):\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "curated_train_samples = filter(filter_xys, train_samples)\n",
    "curated_val_samples = [next(curated_train_samples) for i in range(num_val_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acf9910-b036-438a-b001-9efcd2874683",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, key_curated_train = jax.random.split(key, 2)\n",
    "(\n",
    "    trained_curated_order_1_model,\n",
    "    curated_order_1_steps,\n",
    "    curated_order_1_train_losses,\n",
    "    curated_order_1_val_losses,\n",
    ") = train(\n",
    "    untrained_model,\n",
    "    curated_train_samples,\n",
    "    curated_val_samples,\n",
    "    optim,\n",
    "    order=1,\n",
    "    key=key_curated_train,\n",
    ")\n",
    "\n",
    "plt.semilogy(curated_order_1_steps, curated_order_1_train_losses, label=\"Train\")\n",
    "plt.semilogy(\n",
    "    curated_order_1_steps, curated_order_1_val_losses, \"--\", label=\"Validation\"\n",
    ")\n",
    "plt.title(\"Order 1 (curated)\")\n",
    "plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a4d1b6-01d1-458a-bda1-a48e0181cda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, key_loss_trained = jax.random.split(key, 2)\n",
    "\n",
    "loss(\n",
    "    trained_curated_order_1_model,\n",
    "    next(curated_train_samples),\n",
    "    plot=True,\n",
    "    order=1,\n",
    "    key=key_loss_trained,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b7d83b-ff1e-442f-be17-600520958ea6",
   "metadata": {},
   "source": [
    "### Losses comparison\n",
    "\n",
    "Let's end this notebook by comparing the three different learning losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7498067c-9449-4a3a-9f2b-22291cbbca97",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(order_1_steps, order_1_val_losses, \"--\", label=\"Order 1\")\n",
    "plt.semilogy(order_2_steps, order_2_val_losses, \"--\", label=\"Order 2\")\n",
    "plt.semilogy(\n",
    "    curated_order_1_steps, curated_order_1_val_losses, \"--\", label=\"Order 1 (curated)\"\n",
    ")\n",
    "plt.title(\"Validation losses comparison\")\n",
    "plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
