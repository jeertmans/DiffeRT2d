{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef6e59c4-1cf7-47b8-845e-aab23351901f",
   "metadata": {},
   "source": [
    "# (Improved) Learning to Sample Ray Paths for Faster Ray Tracing\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/jeertmans/DiffeRT2d/blob/main/docs/source/notebooks/cost20120_helsinki_improved_model.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "In this notebook, we present an improved version of\n",
    "our Machine Learning model {cite}`learning-sample-ray-cost-2024`,\n",
    "with inspiration\n",
    "from the Generative Augented Flow Networks see {cite}`gaflownet`.\n",
    "\n",
    "Our model tries to learn how to sample valid ray paths\n",
    "to reduce the overall computational complexity of Ray Tracing (RT).\n",
    "\n",
    "For more details, please refer to the\n",
    "[Python notebook of the base model](./cost20120_helsinki_model.ipynb).\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In the base model, we observed that..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f9311af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few importants imports to be able to run our code\n",
    "# 'type hint' related imports are only here for help documenting the code!\n",
    "\n",
    "try:\n",
    "    import differt2d  # noqa: F401\n",
    "except ImportError:\n",
    "    import sys  # noqa: F401\n",
    "\n",
    "    !{sys.executable} -m pip install git+https://github.com/jeertmans/DiffeRT2d.git\n",
    "\n",
    "from collections.abc import Iterator\n",
    "\n",
    "import equinox as eqx\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import optax\n",
    "from beartype import beartype as typechecker\n",
    "from jaxtyping import Array, Float, Int, PRNGKeyArray, jaxtyped\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "from differt2d.geometry import ImagePath, Point, Wall\n",
    "from differt2d.logic import is_true\n",
    "from differt2d.scene import Scene\n",
    "\n",
    "jax.config.update(\"jax_platform_name\", \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24fa0c3b-61dd-4da7-af37-584b51ebbc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(12345)  # 12345 is the 'random seed'\n",
    "key, key_example_scene = jax.random.split(key, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dfeb25-660d-4cf7-9675-7896234f9eeb",
   "metadata": {},
   "source": [
    "## Training data generation\n",
    "\n",
    "This code is a copy-paste from the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12c60a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_samples(\n",
    "    min_ratio: float = 0.20,\n",
    "    max_ratio: float = 0.40,\n",
    "    min_num_walls: int = 4,\n",
    "    min_angle: float = -0.1 * jnp.pi,\n",
    "    max_angle: float = +0.1 * jnp.pi,\n",
    "    *,\n",
    "    key: PRNGKeyArray,\n",
    ") -> Iterator[Float[Array, \"2+num_walls*2 2\"]]:\n",
    "    \"\"\"\n",
    "    Returns a generator of random variants of :func:`Scene.square_scene_with_obstacle`.\n",
    "\n",
    "    The generation follows a three-steps process:\n",
    "\n",
    "    1. generate a ``square_scene_with_obstacle`` with a random scaling ratio;\n",
    "    2. sample a random number of walls from this scene;\n",
    "    3. and apply a random rotation around the scene's center for each wall.\n",
    "\n",
    "    :param min_ratio: The minimum scaling ratio of the inner square obstacle.\n",
    "    :param min_ratio: The maximum scaling ratio of the inner square obstacle.\n",
    "    :param min_num_walls: The minimum number of walls to sample (maximum is 8).\n",
    "    :param min_angle: The minimum rotation angle (random for each wall).\n",
    "    :param max_angle: The maximum rotation angle (random for each wall).\n",
    "    :param key: The random key to be used.\n",
    "    :return: An iterator over xys samples\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        key, key_ratio, key_tx_rx, key_num_walls, key_walls, key_angles = (\n",
    "            jax.random.split(key, 6)\n",
    "        )\n",
    "        # A random scaling is applied to the inner square\n",
    "        ratio = jax.random.uniform(key_ratio, minval=min_ratio, maxval=max_ratio)\n",
    "        # TX and RX are randomly sampled\n",
    "        points = jax.random.uniform(key_tx_rx, (2, 2))\n",
    "        # The walls are samples from the scene\n",
    "        scene = Scene.square_scene_with_obstacle(ratio=ratio)\n",
    "        center = scene.center()\n",
    "        indices = jnp.arange(len(scene.objects), dtype=jnp.int32)\n",
    "        # The number of walls is random\n",
    "        num_walls = jax.random.randint(\n",
    "            key_num_walls, (), minval=min_num_walls, maxval=len(scene.objects) + 1\n",
    "        )\n",
    "        # Walls are shuffled (to make sure deepset models\n",
    "        # is permutation invariant, but should not be needed)\n",
    "        wall_indices = jax.random.choice(\n",
    "            key_walls, indices, shape=(num_walls,), replace=False\n",
    "        )\n",
    "        # Each wall receives a random permutation around the center of the scene\n",
    "        angles = jax.random.uniform(\n",
    "            key_angles, shape=(num_walls,), minval=min_angle, maxval=max_angle\n",
    "        )\n",
    "        objects = [\n",
    "            scene.objects[wall_index].rotate(angle=angle, around=center)\n",
    "            for wall_index, angle in zip(wall_indices, angles)\n",
    "        ]\n",
    "\n",
    "        points = jnp.vstack([points, *[obj.xys for obj in objects]])\n",
    "\n",
    "        yield points\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def sample_2_scene(xys: Float[Array, \"2+num_walls*2 2\"]) -> Scene:\n",
    "    \"\"\"\n",
    "    Creates the scene corresponding to the given sample.\n",
    "\n",
    "    :param xys: The sample as returned by :func:`random_samples`.\n",
    "    :return: The corresponding scene.\n",
    "    \"\"\"\n",
    "    tx = Point(xy=xys[0, :])\n",
    "    rx = Point(xy=xys[1, :])\n",
    "\n",
    "    walls = xys[2:].reshape(-1, 2, 2)\n",
    "    walls = [Wall(xys=wall) for wall in walls]\n",
    "\n",
    "    return Scene(transmitters={\"tx\": tx}, receivers={\"rx\": rx}, objects=walls)\n",
    "\n",
    "\n",
    "samples = random_samples(key=key_example_scene)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6369c1-55bd-45ae-a5ef-16def56cd3f7",
   "metadata": {},
   "source": [
    "=(random-scene-example)\n",
    "### Example of random scene\n",
    "\n",
    "Below, we can see one of the random scenes generated by our function defined just before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5eabdeb5-1f97-4745-b4db-bdb17205e7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0909 11:57:38.667814  103914 pjrt_stream_executor_client.cc:3067] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Failed to load in-memory CUBIN (compiled for a different GPU?).: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    },
    {
     "ename": "XlaRuntimeError",
     "evalue": "RESOURCE_EXHAUSTED: Failed to load in-memory CUBIN (compiled for a different GPU?).: CUDA_ERROR_OUT_OF_MEMORY: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run this cell multiple times for different results!\u001b[39;00m\n\u001b[1;32m      3\u001b[0m ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mgca()\n\u001b[0;32m----> 4\u001b[0m scene \u001b[38;5;241m=\u001b[39m sample_2_scene(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      5\u001b[0m scene\u001b[38;5;241m.\u001b[39mplot(ax)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, _, path, _ \u001b[38;5;129;01min\u001b[39;00m scene\u001b[38;5;241m.\u001b[39mall_valid_paths(order\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n",
      "Cell \u001b[0;32mIn[3], line 52\u001b[0m, in \u001b[0;36mrandom_samples\u001b[0;34m(min_ratio, max_ratio, min_num_walls, min_angle, max_angle, key)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Each wall receives a random permutation around the center of the scene\u001b[39;00m\n\u001b[1;32m     49\u001b[0m angles \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\n\u001b[1;32m     50\u001b[0m     key_angles, shape\u001b[38;5;241m=\u001b[39m(num_walls,), minval\u001b[38;5;241m=\u001b[39mmin_angle, maxval\u001b[38;5;241m=\u001b[39mmax_angle\n\u001b[1;32m     51\u001b[0m )\n\u001b[0;32m---> 52\u001b[0m objects \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscene\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjects\u001b[49m\u001b[43m[\u001b[49m\u001b[43mwall_index\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrotate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mangle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mangle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maround\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcenter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwall_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mangle\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwall_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mangles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     57\u001b[0m points \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mvstack([points, \u001b[38;5;241m*\u001b[39m[obj\u001b[38;5;241m.\u001b[39mxys \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m objects]])\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m points\n",
      "Cell \u001b[0;32mIn[3], line 53\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Each wall receives a random permutation around the center of the scene\u001b[39;00m\n\u001b[1;32m     49\u001b[0m angles \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\n\u001b[1;32m     50\u001b[0m     key_angles, shape\u001b[38;5;241m=\u001b[39m(num_walls,), minval\u001b[38;5;241m=\u001b[39mmin_angle, maxval\u001b[38;5;241m=\u001b[39mmax_angle\n\u001b[1;32m     51\u001b[0m )\n\u001b[1;32m     52\u001b[0m objects \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 53\u001b[0m     \u001b[43mscene\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjects\u001b[49m\u001b[43m[\u001b[49m\u001b[43mwall_index\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrotate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mangle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mangle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maround\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcenter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m wall_index, angle \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(wall_indices, angles)\n\u001b[1;32m     55\u001b[0m ]\n\u001b[1;32m     57\u001b[0m points \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mvstack([points, \u001b[38;5;241m*\u001b[39m[obj\u001b[38;5;241m.\u001b[39mxys \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m objects]])\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m points\n",
      "    \u001b[0;31m[... skipping hidden 10 frame]\u001b[0m\n",
      "File \u001b[0;32m~/repositories/DiffeRT/DiffeRT2d/.venv/lib/python3.11/site-packages/jax/_src/interpreters/pxla.py:1248\u001b[0m, in \u001b[0;36mExecuteReplicated.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1246\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_token_bufs(result_token_bufs, sharded_runtime_token)\n\u001b[1;32m   1247\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1248\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxla_executable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_sharded\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_bufs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dispatch\u001b[38;5;241m.\u001b[39mneeds_check_special():\n\u001b[1;32m   1251\u001b[0m   out_arrays \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mdisassemble_into_single_device_arrays()\n",
      "\u001b[0;31mXlaRuntimeError\u001b[0m: RESOURCE_EXHAUSTED: Failed to load in-memory CUBIN (compiled for a different GPU?).: CUDA_ERROR_OUT_OF_MEMORY: out of memory"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell multiple times for different results!\n",
    "\n",
    "ax = plt.gca()\n",
    "scene = sample_2_scene(next(samples))\n",
    "scene.plot(ax)\n",
    "\n",
    "for _, _, path, _ in scene.all_valid_paths(order=2):\n",
    "    path.plot(ax)\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741db7a8-3530-450d-ac97-3dbf7eccfe24",
   "metadata": {},
   "source": [
    "### Training and validation samples\n",
    "\n",
    "Because our data generation produces a never-ending sequence of\n",
    "samples, each sample being unique, we can very well take the 100 first samples\n",
    "and use them as a validation set.\n",
    "\n",
    "Using 100 samples is a bit arbitrary, as it assumes that those 100\n",
    "samples can be representative of the distribution of all possible\n",
    "scenes. We will discuss that assumptions in the [discussion](#discussion)\n",
    "section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac336913-6a59-4eda-9ddc-621fc12b9a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, key_samples = jax.random.split(key, 2)\n",
    "\n",
    "# Let's filter out the cases with not valid paths,\n",
    "# because they are not interesting to learn from.\n",
    "\n",
    "num_val_samples = 100\n",
    "\n",
    "train_samples = random_samples(key=key_samples)\n",
    "\n",
    "val_samples = [next(train_samples) for i in range(num_val_samples)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ed2260-d750-4b06-a127-625ad1688489",
   "metadata": {},
   "source": [
    "## Reward function\n",
    "\n",
    "To indicate our model which path candidates should be sampled\n",
    "(and which paths should not), we define a *reward* function.\n",
    "\n",
    "The goal of the reward function is to give a high reward to valid paths,\n",
    "and and a low reward to invalid ones.\n",
    "\n",
    "The simplest reward possible is the following: valid path candidates\n",
    "receive a reward of 1, while invalid path candidates receive no reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec513edd-a2d1-475e-91b7-81430bf7ab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "@jaxtyped(typechecker=typechecker)\n",
    "def reward(\n",
    "    pred_path_candidate: Int[Array, \"order\"],\n",
    "    scene: Scene,\n",
    ") -> Float[Array, \" \"]:\n",
    "    \"\"\"\n",
    "    Rewards a predicted path candidate depending on if it\n",
    "    produces a valid path in the given scene.\n",
    "\n",
    "    :param pred_path_candidate: The predicted path candidate.\n",
    "    :param scene: The scene in which the path is traced.\n",
    "    :return: The (positive) reward.\n",
    "    \"\"\"\n",
    "    tx = scene.transmitters[\"tx\"]\n",
    "    rx = scene.receivers[\"rx\"]\n",
    "\n",
    "    # The following it a JIT-compatible variant of scene.get_interacting_objects\n",
    "    xys = jnp.stack(\n",
    "        [wall.xys for wall in scene.objects]\n",
    "    )  # Stack all walls into one array\n",
    "    interacting_walls = jnp.take(xys, pred_path_candidate, axis=0)\n",
    "    interacting_walls = [Wall(xys=wall) for wall in interacting_walls]\n",
    "\n",
    "    path = ImagePath.from_tx_objects_rx(tx, interacting_walls, rx)\n",
    "    valid = path.is_valid(scene.objects, pred_path_candidate, interacting_walls)\n",
    "\n",
    "    return valid.astype(float)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "@jaxtyped(typechecker=typechecker)\n",
    "def intermediate_reward(\n",
    "    intermediate_path_candidate: Int[Array, \"intermediate_order\"],\n",
    "    scene: Scene,\n",
    "    *,\n",
    "    key: PRNGKeyArray,\n",
    ") -> Float[Array, \" \"]:\n",
    "    \"\"\"\n",
    "    Rewards an intermediate path candidate depending on if it could\n",
    "    produce a valid path in the given scene.\n",
    "\n",
    "    :param intermediate_path_candidate: The intermediate path candidate.\n",
    "    :param scene: The scene in which the path is traced.\n",
    "    :return: The (positive) reward.\n",
    "    \"\"\"\n",
    "    assert intermediate_path_candidate.size > 0\n",
    "    last_wall_index = intermediate_path_candidate[-1]\n",
    "    last_wall = scene.get_object(last_wall_index)\n",
    "\n",
    "    scene = scene.with_receivers(rx=last_wall.sample(key=key))\n",
    "\n",
    "    return reward(intermediate_path_candidate[:-1], scene)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac4d34c-7402-48d8-a797-296911d4328e",
   "metadata": {},
   "source": [
    "Let us take a look at the rewards of the different path candidates from the above scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e61089-be16-4561-bb5d-515a57a36976",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "scene.plot(ax)\n",
    "\n",
    "for _, _, valid, path, path_candidate in scene.all_paths(order=order):\n",
    "    if is_true(valid):\n",
    "        path.plot(ax)\n",
    "        s = \"valid  :\"\n",
    "    else:\n",
    "        s = \"invalid:\"\n",
    "\n",
    "    p = path_candidate.tolist()\n",
    "    r = reward(path_candidate, scene)\n",
    "\n",
    "    print(f\"{s} path_candidate = {p} has a reward of {r}\")\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f48cbad-fbad-456a-aff0-8ed66c850d1b",
   "metadata": {},
   "source": [
    "## Model definition\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c985f39b-501f-4c4a-abdf-474c1568ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowModel(eqx.Module):\n",
    "    \"\"\"The flow model that returns flows between two states.\"\"\"\n",
    "\n",
    "    # Layers\n",
    "    wall_2_embeddings: eqx.nn.MLP\n",
    "    \"\"\"MLP that is applied to each wall in parallel and\n",
    "    returns the corresponding embeddings.\"\"\"\n",
    "    embeddings_2_flow: eqx.nn.MLP\n",
    "    \"\"\"MLP that maps each possible choice to some positive flow.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        # Hyperparameters\n",
    "        num_embeddings: int = 100,\n",
    "        *,\n",
    "        key: PRNGKeyArray,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Constructs a GFlowNet model.\n",
    "\n",
    "        :param num_embeddings: The size of the vector that will represent each wall.\n",
    "        :param key: The random key to be used.\n",
    "        \"\"\"\n",
    "        key1, key2 = jax.random.split(key, 2)\n",
    "\n",
    "        # Layers\n",
    "        self.wall_2_embeddings = eqx.nn.MLP(\n",
    "            in_size=4,\n",
    "            out_size=num_embeddings,\n",
    "            width_size=500,\n",
    "            depth=3,\n",
    "            key=key1,\n",
    "        )\n",
    "        self.embeddings_2_flow = eqx.nn.MLP(\n",
    "            in_size=4\n",
    "            + 2 * num_embeddings\n",
    "            + 4,  # [tx_rx, state_embeddings, scene_embeddings, wall[i]]\n",
    "            out_size=\"scalar\",\n",
    "            width_size=500,\n",
    "            depth=3,\n",
    "            final_activation=jnp.exp,  # Positive flow only\n",
    "            key=key2,\n",
    "        )\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    @jaxtyped(typechecker=typechecker)\n",
    "    def __call__(\n",
    "        self,\n",
    "        state: Float[Array, \"num_walls order\"],\n",
    "        wall_index: Int[Array, \" \"],\n",
    "        xys: Float[Array, \"2+num_walls*2 2\"],\n",
    "    ) -> Float[Array, \"num_walls\"]:\n",
    "        \"\"\"\n",
    "        Calls this model in order to generate a new flow from a given state,\n",
    "        the last selected wall index, and some input scene.\n",
    "\n",
    "        :param state: The current state, a one-hot encoding of the path candidate\n",
    "            in construction. Only one element per column can be non-zero.\n",
    "        :param wall_index: The index of the last wall that was selected. A negative index\n",
    "            indicates that no wall was previously selected.\n",
    "        :param xys: The array of xy-coordinates, as returned by\n",
    "            :func:`random_samples`.\n",
    "        :return: The array of flows, one per wall in the scene.\n",
    "        \"\"\"\n",
    "        assert (\n",
    "            xys.shape[0] >= 4\n",
    "        ), \"Scene must at least have two points, tx and rx, and one wall!\"\n",
    "\n",
    "        num_walls, order = state.shape\n",
    "\n",
    "        # Data normalization\n",
    "        eps = 1e-5\n",
    "        center = jnp.at_least2d(xys[0, :])  # We arbitrarily put tx at the center\n",
    "        std = jnp.std(xys, axis=0, keepdims=True)\n",
    "\n",
    "        xys = (xys - center) / (std + eps)\n",
    "\n",
    "        # Rotation invariance\n",
    "        direction = xys[1, :]  # tx and rx make an horizontal line\n",
    "        angle = jnp.atan2(direction[1], direction[0])\n",
    "        s = jnp.sin(angle)\n",
    "        c = jnp.cos(angle)\n",
    "        rotation = jnp.array([[+c, -s], [+s, +c]])\n",
    "        xys = (rotation @ xys.T).T\n",
    "\n",
    "        tx_rx = xys[:2, :].reshape(4)\n",
    "        walls = xys[2:, :].reshape(num_walls, 4)\n",
    "\n",
    "        # [num_walls 4]\n",
    "        # note: this input we be the same for every wall\n",
    "        tx_rx = jnp.tile(tx_rx, (num_walls, 1))\n",
    "\n",
    "        # [num_walls num_embeddings]\n",
    "        # note: each wall is mapped to a vector of embeddings\n",
    "        walls_embeddings = jax.vmap(self.wall_2_embeddings)(walls)\n",
    "\n",
    "        # [num_embeddings]\n",
    "        # note: the scene is the sum of all embeddings\n",
    "        scene_embeddings = jnp.sum(walls_embeddings, axis=0)\n",
    "\n",
    "        # [num_walls num_embeddings]\n",
    "        # note: this input we be the same for every wall\n",
    "        scene_embeddings = jnp.tile(scene_embeddings, (num_walls, 1))\n",
    "\n",
    "        # [order]\n",
    "        # note: fill_value=num_walls is important as we need to generate 'out of bounds'\n",
    "        #       indices for missing values (only current_order <= order are non zero)\n",
    "        wall_indices, _ = jnp.nonzero(state, size=order, fill_value=num_walls)\n",
    "\n",
    "        # [order num_embeddings]\n",
    "        # note: we tell JAX to replace 'out of bounds' indices with zeros,\n",
    "        #       as this will have no impact on the sum (see next step)\n",
    "        state_embeddings = jnp.take(\n",
    "            walls_embeddings, wall_indices, axis=0, fill_value=0\n",
    "        )\n",
    "\n",
    "        # [num_embeddings]\n",
    "        # note: this contains information about the walls we already visited,\n",
    "        #       as a sum of corresponding embeddings (one wall can appear multiple times)\n",
    "        state_embeddings = jnp.sum(state_embeddings, axis=0)\n",
    "\n",
    "        # [num_walls num_embeddings]\n",
    "        # note: this input we be the same for every wall\n",
    "        state_embeddings = jnp.tile(state_embeddings, (num_walls, 1))\n",
    "\n",
    "        # [num_walls]\n",
    "        # note: the input (per wall) looks as follows\n",
    "        #       # [tx_rx, state_embeddings, scene_embeddings, wall[i]]\n",
    "        flow = jax.vmap(self.embeddings_2_flow)(\n",
    "            jnp.hstack((tx_rx, state_embeddings, scene_embeddings, walls))\n",
    "        )\n",
    "\n",
    "        # Set flow[wall_index] to zero to prevent consecutive duplicate indices\n",
    "        # A flow of zero means that there is a zero probability to pick\n",
    "        # walls[wall_index] for the next state.\n",
    "        flow = flow.at[wall_index].set(0.0)  # out of bounds indices are ignored\n",
    "\n",
    "        return flow\n",
    "\n",
    "\n",
    "class Model(eqx.Module):\n",
    "    \"\"\"The generative model that samples a path candidate from flows.\"\"\"\n",
    "\n",
    "    flow: FlowModel\n",
    "    \"\"\"The learnable flow model.\"\"\"\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def __call__(\n",
    "        self,\n",
    "        xys: Float[Array, \"2+num_walls*2 2\"],\n",
    "        *,\n",
    "        order: int,\n",
    "        key: PRNGKeyArray,\n",
    "    ) -> Int[Array, \"{order}\"]:\n",
    "        \"\"\"\n",
    "        Calls this model to generate a path candidate of the given order.\n",
    "\n",
    "        :param xys: The array of xy-coordinates, as returned by\n",
    "            :func:`random_samples`.\n",
    "        :param order: The order of the path candidate.\n",
    "        :param key: The random key to be used.\n",
    "        :return: A path candidate.\n",
    "        \"\"\"\n",
    "        # See loss function for detailed comments\n",
    "        num_walls = (xys.shape[0] - 2) // 2\n",
    "\n",
    "        ScanR = Int[Array, \" \"]\n",
    "        ScanC = tuple[\n",
    "            Float[Array, \" num_walls\"],\n",
    "            Float[Array, \"num_walls order\"],\n",
    "        ]\n",
    "\n",
    "        @jaxtyped(typechecker=typechecker)\n",
    "        def scan_fn(\n",
    "            carry: ScanC, key_and_current_order: tuple[PRNGKeyArray, Int[Array, \" \"]]\n",
    "        ) -> tuple[ScanC, ScanR]:\n",
    "            parent_edge_flow_prediction, state = carry\n",
    "            key, current_order = key_and_current_order\n",
    "\n",
    "            p = parent_edge_flow_prediction / jnp.sum(parent_edge_flow_prediction)\n",
    "\n",
    "            wall_index = jax.random.categorical(key=key, logits=jnp.log(p))\n",
    "\n",
    "            state = state.at[wall_index, current_order].set(1.0)\n",
    "\n",
    "            edge_flow_prediction = self.flow(state, wall_index, xys)\n",
    "\n",
    "            return (edge_flow_prediction, state), wall_index\n",
    "\n",
    "        wall_index = jnp.array(num_walls)\n",
    "        state = jnp.zeros((num_walls, order))\n",
    "        parent_edge_flow_prediction = self.flow(state, wall_index, xys)\n",
    "        init = parent_edge_flow_prediction, state\n",
    "        _, pred_path_candidate = jax.lax.scan(\n",
    "            scan_fn,\n",
    "            init,\n",
    "            xs=(jax.random.split(key, order), jnp.arange(order)),\n",
    "        )\n",
    "\n",
    "        return pred_path_candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7470ffd2-f9c3-4e68-a535-c3848af1a60f",
   "metadata": {},
   "source": [
    "## Loss function definition\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be7b365-8559-4413-8485-a6126cebee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jaxtyped(typechecker=None)\n",
    "def loss(\n",
    "    model: FlowModel,\n",
    "    xys: Float[Array, \"2+num_walls*2 2\"],\n",
    "    batch_size: int = 10,\n",
    "    plot: bool = False,\n",
    "    *,\n",
    "    order: int,\n",
    "    key: PRNGKeyArray,\n",
    ") -> Float[Array, \" \"]:\n",
    "    \"\"\"\n",
    "    Compute the loss of the model on a specific input scene.\n",
    "\n",
    "    The loss is accumulated over the generation of 'batch_size' path candidates.\n",
    "    \"\"\"\n",
    "    num_walls = (xys.shape[0] - 2) // 2\n",
    "    scene = sample_2_scene(xys)\n",
    "\n",
    "    BatchC = Float[Array, \" \"]\n",
    "    BatchR = Int[Array, \" order\"]\n",
    "\n",
    "    @jaxtyped(typechecker=typechecker)\n",
    "    def batch_fn(batch_loss: BatchC, key: PRNGKeyArray) -> tuple[BatchC, BatchR]:\n",
    "        flow_mismatch = jnp.array(0.0)\n",
    "        wall_index = jnp.array(\n",
    "            num_walls\n",
    "        )  # We didn't select any wall yet: out of bounds index\n",
    "        state = jnp.zeros(\n",
    "            (num_walls, order)\n",
    "        )  # Same, but represented in one-hot encoding\n",
    "        parent_edge_flow_prediction = model(\n",
    "            state, wall_index, xys\n",
    "        )  # Initial state's flow\n",
    "        pred_path_candidate = jnp.full(order, num_walls, dtype=int)\n",
    "\n",
    "        for current_order, key_loop in enumerate(jax.random.split(key, order)):\n",
    "            # Turn positive flow into normalized probability in [0, 1]\n",
    "            p = parent_edge_flow_prediction / jnp.sum(parent_edge_flow_prediction)\n",
    "\n",
    "            key_index, key_intermediate_reward = jax.random.split(key_loop, 2)\n",
    "\n",
    "            wall_index = jax.random.categorical(\n",
    "                key=key_index, logits=jnp.log(p)\n",
    "            )  # The wall to choose\n",
    "\n",
    "            # Indicate we have chosen walls[wall_index] as a candidate at 'current_order'\n",
    "            state = state.at[wall_index, current_order].set(1.0)\n",
    "            pred_path_candidate = pred_path_candidate.at[current_order].set(wall_index)\n",
    "\n",
    "            edge_flow_prediction = model(state, wall_index, xys)\n",
    "\n",
    "            if current_order == order - 1:  # Check whether we reached final state\n",
    "                r = reward(pred_path_candidate, scene)\n",
    "                flow_mismatch += (\n",
    "                    (  # Reached last state so (next) edge_flow_prediction is ignored\n",
    "                        parent_edge_flow_prediction[\n",
    "                            wall_index\n",
    "                        ]  # Each state s' has only one possible parent state s\n",
    "                        - r\n",
    "                    )\n",
    "                    ** 2\n",
    "                )\n",
    "            else:\n",
    "                ir = intermediate_reward(\n",
    "                    pred_path_candidate[: current_order + 1],\n",
    "                    scene,\n",
    "                    key=key_intermediate_reward,\n",
    "                )\n",
    "                flow_mismatch += (  # Didn't reach last state so no reward\n",
    "                    parent_edge_flow_prediction[\n",
    "                        wall_index\n",
    "                    ]  # Each state s' has only one possible parent state s\n",
    "                    - jnp.sum(edge_flow_prediction)\n",
    "                    - ir\n",
    "                ) ** 2\n",
    "\n",
    "        return batch_loss + flow_mismatch, pred_path_candidate\n",
    "\n",
    "    batch_loss = jnp.array(0.0)\n",
    "    batch_loss, pred_path_candidates = jax.lax.scan(\n",
    "        batch_fn, batch_loss, xs=jax.random.split(key, batch_size)\n",
    "    )\n",
    "\n",
    "    if plot:  # Let's see the prediction vs ground truth\n",
    "        ax = plt.gca()\n",
    "        scene.plot(ax)\n",
    "        ax.set_xlim(-0.1, 1.1)\n",
    "        ax.set_ylim(-0.1, 1.1)\n",
    "        tx = scene.transmitters[\"tx\"]\n",
    "        rx = scene.receivers[\"rx\"]\n",
    "\n",
    "        gt = None\n",
    "        for _, _, path, _ in scene.all_valid_paths(order=order):\n",
    "            (gt,) = path.plot(ax, color=\"orange\")\n",
    "\n",
    "        if gt is not None:\n",
    "            gt.set_label(\"Ground Truth\")\n",
    "\n",
    "        n_unique = 0\n",
    "        pr = None\n",
    "        for pred_path_candidate in jnp.unique(pred_path_candidates, axis=0):\n",
    "            n_unique += 1\n",
    "            objects = [scene.objects[i] for i in pred_path_candidate]\n",
    "            (pr,) = ImagePath.from_tx_objects_rx(tx, objects, rx).plot(\n",
    "                ax, linestyle=\"--\", alpha=0.5, color=\"red\"\n",
    "            )\n",
    "\n",
    "        if pr is not None:\n",
    "            pr.set_label(\"Prediction\")\n",
    "\n",
    "        ax.set_title(\n",
    "            f\"Generated {batch_size} path cand. (of which {n_unique} are unique)\"\n",
    "        )\n",
    "        ax.set_xlabel(\"x coordinate\")\n",
    "        ax.set_ylabel(\"y coordinate\")\n",
    "        ax.legend()\n",
    "        plt.show()\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651b14d9-57cb-48e5-a438-c9e0204e06e5",
   "metadata": {},
   "source": [
    "### Evaluating the loss on an untrained model\n",
    "\n",
    "The following code shows how to initialize the model and\n",
    "how the loss function works. The order of paths must be specified\n",
    "at this will tell the loss function how many times the flow model\n",
    "should be called.\n",
    "\n",
    "To change the order of the generated path candidates,\n",
    "you just need to change the value of the `order=K` keyword-only argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf67f8a-b55a-4449-bdce-6a1fd6bf25fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, key_model = jax.random.split(key, 2)\n",
    "untrained_model = FlowModel(key=key_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7cb03a-b637-4fc5-bd98-129c48844f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell multiple times for different results!\n",
    "\n",
    "key, key_loss_untrained = jax.random.split(key, 2)\n",
    "loss(\n",
    "    untrained_model, next(train_samples), plot=True, order=1, key=key_loss_untrained\n",
    ")  # Untrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737b698a-6b75-4d5e-9f5c-e640efedb8d8",
   "metadata": {},
   "source": [
    "## Training phase\n",
    "\n",
    "In the proposed architecture, only the `FlowModel` needs to be trained.\n",
    "\n",
    "As a result, we defined a loss function directly deals with this model,\n",
    "and not with the `Model` class, and the learning procedure looks a bit\n",
    "like in the graph below.\n",
    "\n",
    "```{mermaid}\n",
    ":align: center\n",
    ":caption: Graph of the (simplified) learning process.\n",
    "\n",
    "graph LR\n",
    "    GE[[Geometry]]\n",
    "    PC((Flow<br>model))\n",
    "    R(Reward)\n",
    "    G(Gradients)\n",
    "\n",
    "    subgraph Loss\n",
    "        PC\n",
    "        R\n",
    "    end\n",
    "\n",
    "    PC --> |order times| PC\n",
    "    GE --> PC\n",
    "    PC -->|\"Path candidate\"| R\n",
    "    R --> |Loss| G\n",
    "    G -->|Update| PC\n",
    "```\n",
    "\n",
    "The training function is very simple, as it the complex part\n",
    "of performing the gradients update is done by {mod}`optax`.\n",
    "We decide to use one of the most popular model, Adam {cite}`adam`,\n",
    "but one could think of other optimizers (or meta-parameters)\n",
    "that may be best suited to this problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b8cc6c-23f7-4317-982f-f225efb9de82",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = optax.adam(learning_rate=3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930a3ef7-345b-4e47-993e-64944701a597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: FlowModel,\n",
    "    train_samples: Iterator[Float[Array, \"2+num_walls*2 2\"]],\n",
    "    val_samples: list[Float[Array, \"2+num_walls*2 2\"]],\n",
    "    optim: optax.GradientTransformation,\n",
    "    steps: int = 100,\n",
    "    print_every: int = 100,\n",
    "    *,\n",
    "    order: int,\n",
    "    key: PRNGKeyArray,\n",
    ") -> tuple[\n",
    "    FlowModel,\n",
    "    Float[Array, \"{steps}//{print_every}\"],\n",
    "    Float[Array, \"{steps}//{print_every}\"],\n",
    "    Float[Array, \"{steps}//{print_every}\"],\n",
    "]:\n",
    "    \"\"\"\n",
    "    Trains a flow model on a sequence of training samples and returns the averaged loss over validation samples.\n",
    "\n",
    "    :param model: The model to train.\n",
    "    :param train_samples: The training samples.\n",
    "    :param val_samples: The validation samples.\n",
    "    :param optim: The optimizer to use.\n",
    "    :param steps: The number of optimization steps.\n",
    "    :param print_every: The frequency at which the average loss is computed.\n",
    "    :param order: The order of the paths to be trained on.\n",
    "    :param key: The random key to be used.\n",
    "    :return: The trained model, the steps,\n",
    "        the train losses and the validation losses.\n",
    "    \"\"\"\n",
    "    opt_state = optim.init(eqx.filter(model, eqx.is_array))\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def make_step(\n",
    "        model: FlowModel,\n",
    "        opt_state: optax.OptState,\n",
    "        xys: Float[Array, \"2+num_walls*2 2\"],\n",
    "        *,\n",
    "        order: int,\n",
    "        key: PRNGKeyArray,\n",
    "    ):\n",
    "        loss_value, grads = eqx.filter_value_and_grad(loss)(\n",
    "            model, xys, order=order, key=key\n",
    "        )\n",
    "        updates, opt_state = optim.update(grads, opt_state, model)\n",
    "        model = eqx.apply_updates(model, updates)\n",
    "        return model, opt_state, loss_value\n",
    "\n",
    "    loss_steps = []\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    jitted_loss = eqx.filter_jit(loss)\n",
    "\n",
    "    with trange(steps, desc=\"\", unit=\" steps\", leave=True) as bar:\n",
    "        for (\n",
    "            step,\n",
    "            xys_train,\n",
    "        ) in zip(bar, train_samples):\n",
    "            key, key_step = jax.random.split(key, 2)\n",
    "\n",
    "            model, opt_state, train_loss = make_step(\n",
    "                model, opt_state, xys_train, order=order, key=key_step\n",
    "            )\n",
    "\n",
    "            if (step % print_every) == 0 or (step == steps - 1):\n",
    "                # Only update the training 'bar' every few steps\n",
    "                val_loss = 0.0\n",
    "                for xys_val in val_samples:\n",
    "                    key, key_val = jax.random.split(key, 2)\n",
    "                    val_loss += jitted_loss(model, xys_val, order=order, key=key_val)\n",
    "\n",
    "                val_loss /= len(val_samples)\n",
    "\n",
    "                loss_steps.append(step)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "\n",
    "                bar.set_description(\n",
    "                    f\"train_loss = {float(train_loss):.1f}, \"\n",
    "                    f\"val_loss = {float(val_loss):.1f}\"\n",
    "                )\n",
    "\n",
    "    return model, jnp.array(loss_steps), jnp.array(train_losses), jnp.array(val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c8c647-d73c-4b8b-95ef-156aed564610",
   "metadata": {},
   "source": [
    "### First order paths\n",
    "\n",
    "Below, we show the training process for learning how to sample first-order\n",
    "path candidates. As you can see from the plot of the loss function,\n",
    "the learning is not excellent, but we can observe that the model\n",
    "often returns valid path candidates, and that we don't just have\n",
    "`batch_size=10` random path candidates that are all different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c04eb13-9336-49d5-aecb-8588b265f13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, key_train = jax.random.split(key, 2)\n",
    "\n",
    "trained_model_order_1, order_1_steps, order_1_train_losses, order_1_val_losses = train(\n",
    "    untrained_model, train_samples, val_samples, optim, order=1, key=key_train\n",
    ")\n",
    "\n",
    "plt.semilogy(order_1_steps, order_1_train_losses, label=\"Train\")\n",
    "plt.semilogy(order_1_steps, order_1_val_losses, \"--\", label=\"Validation\")\n",
    "plt.title(\"Order 1\")\n",
    "plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d50bd34-18d6-40d8-bf15-e5ebb8be286c",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, key_loss_trained = jax.random.split(key, 2)\n",
    "\n",
    "loss(\n",
    "    trained_model_order_1, next(train_samples), plot=True, order=1, key=key_loss_trained\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db49c67c-c136-4738-b0bf-d9a1be767088",
   "metadata": {},
   "source": [
    "### Second order paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ecfc03-a8a9-4265-a440-5edf7b25bdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, key_train = jax.random.split(key, 2)\n",
    "\n",
    "trained_model_order_2, order_2_steps, order_2_train_losses, order_2_val_losses = train(\n",
    "    untrained_model, train_samples, val_samples, optim, order=2, key=key_train\n",
    ")\n",
    "\n",
    "plt.semilogy(order_2_steps, order_2_train_losses, label=\"Train\")\n",
    "plt.semilogy(order_2_steps, order_2_val_losses, \"--\", label=\"Validation\")\n",
    "plt.title(\"Order 2\")\n",
    "plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef52320-0e1d-4463-8eb4-737ca97e3bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell multiple times for different results!\n",
    "key, key_loss_trained = jax.random.split(key, 2)\n",
    "\n",
    "loss(\n",
    "    trained_model_order_2, next(train_samples), plot=True, order=2, key=key_loss_trained\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d297052-23b9-43fa-a837-c4deca8fe3da",
   "metadata": {},
   "source": [
    "Alternatively, we could use the `trained_model_order_1` to generate\n",
    "second-order path candidates, hoping that it generalizes well\n",
    "on higher orders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe511be-0255-42b6-ab64-7f8c604699fe",
   "metadata": {},
   "source": [
    "## Inference phase\n",
    "\n",
    "Once the model has been trained, we can instantiate a complete Machine Learning\n",
    "model to sample path candidates. In itself, the `Model` class is just a plan\n",
    "wrapper around the trained `FlowModel` instance, that will call\n",
    "it repeatedly to generate path candidates of a given size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b806ea50-1a7f-4f79-87a1-8934baeed9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    flow=eqx.nn.inference_mode(\n",
    "        trained_model_order_2\n",
    "    )  # Here, this is a no-op (just copies the model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ef95aa-37cc-48a4-b098-33a3c202c082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell multiple times for different results!\n",
    "\n",
    "key, key_inference = jax.random.split(key, 2)\n",
    "\n",
    "model(next(train_samples), order=2, key=key_inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f0fa52-4b4d-44a5-8242-4441b01aded8",
   "metadata": {},
   "source": [
    "=(discussion)\n",
    "## Discussion\n",
    "\n",
    "In complement to what is discussed in our paper, we highlight the following \n",
    "future prospects:\n",
    "- removing from the training data the scenes that **do not contain any valid path**:\n",
    "  they are not actually very interesting for our problem, and may have a detrimental impact on the\n",
    "  learning process as the model will not receive any reward;\n",
    "- to enhance generalization, we also could think of accumulating the loss on several scenes, rather than one scene at a time;\n",
    "- and investigate a solution that aims to mitigate to impact of sparse reward functions, as in our case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc66ffb9-5d90-4094-a32c-9e329b70c195",
   "metadata": {},
   "source": [
    "## Appendix - Training on curated scenes\n",
    "\n",
    "As suggested in the [discussion](#discussion), we show how the training\n",
    "on a curated training dataset, i.e., with some scenes removed,\n",
    "can help improving the learning process.\n",
    "\n",
    "Here, the `filter_xys` function just returns `True` if the scene\n",
    "will at least contain one valid ray path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af102125-5fa4-485b-af4a-a63134d1e37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_xys(xys: Float[Array, \"2+num_walls*2 2\"]) -> bool:\n",
    "    \"\"\"\n",
    "    Returns True if the scene contains at least one valid path.\n",
    "\n",
    "    :param xys: The input scene.\n",
    "    :return: True if the scene should be kept.\n",
    "    \"\"\"\n",
    "    scene = sample_2_scene(xys)\n",
    "\n",
    "    for _ in scene.all_valid_paths(order=order):\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "curated_train_samples = filter(filter_xys, train_samples)\n",
    "curated_val_samples = [next(curated_train_samples) for i in range(num_val_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acf9910-b036-438a-b001-9efcd2874683",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, key_curated_train = jax.random.split(key, 2)\n",
    "(\n",
    "    trained_curated_order_1_model,\n",
    "    curated_order_1_steps,\n",
    "    curated_order_1_train_losses,\n",
    "    curated_order_1_val_losses,\n",
    ") = train(\n",
    "    untrained_model,\n",
    "    curated_train_samples,\n",
    "    curated_val_samples,\n",
    "    optim,\n",
    "    order=1,\n",
    "    key=key_curated_train,\n",
    ")\n",
    "\n",
    "plt.semilogy(curated_order_1_steps, curated_order_1_train_losses, label=\"Train\")\n",
    "plt.semilogy(\n",
    "    curated_order_1_steps, curated_order_1_val_losses, \"--\", label=\"Validation\"\n",
    ")\n",
    "plt.title(\"Order 1 (curated)\")\n",
    "plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a4d1b6-01d1-458a-bda1-a48e0181cda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, key_loss_trained = jax.random.split(key, 2)\n",
    "\n",
    "loss(\n",
    "    trained_curated_order_1_model,\n",
    "    next(curated_train_samples),\n",
    "    plot=True,\n",
    "    order=1,\n",
    "    key=key_loss_trained,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b7d83b-ff1e-442f-be17-600520958ea6",
   "metadata": {},
   "source": [
    "### Losses comparison\n",
    "\n",
    "Let's end this notebook by comparing the three different learning losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7498067c-9449-4a3a-9f2b-22291cbbca97",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(order_1_steps, order_1_val_losses, \"--\", label=\"Order 1\")\n",
    "plt.semilogy(order_2_steps, order_2_val_losses, \"--\", label=\"Order 2\")\n",
    "plt.semilogy(\n",
    "    curated_order_1_steps, curated_order_1_val_losses, \"--\", label=\"Order 1 (curated)\"\n",
    ")\n",
    "plt.title(\"Validation losses comparison\")\n",
    "plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
