{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef6e59c4-1cf7-47b8-845e-aab23351901f",
   "metadata": {},
   "source": [
    "# Learning to Sample Ray Paths for Faster Ray Tracing\n",
    "\n",
    "In this notebook, we present a Machine Learning model,\n",
    "based on the GFlowNet architecture {cite}`gflownet`,\n",
    "that tries to learn how to sample valid ray paths\n",
    "to reduce the overall computational complexity of Ray Tracing (RT).\n",
    "\n",
    "Our model also takes inspiration from the Deep Sets\n",
    "{cite}`deepsets` to provide invariance with permutations in the input,\n",
    "as well as allowing to scene to be arbitrary large.\n",
    "\n",
    ":::{note}\n",
    "When writing this notebook and the Machine Learning Model,\n",
    "we took a great inspiration from the [GFlowNet tutorial from Emmanuel Bengio](https://colab.research.google.com/drive/1fUMwgu2OhYpQagpzU5mhe9_Esib3Q2VR).\n",
    ":::\n",
    "\n",
    ":::{warning}\n",
    "This notebook only shows a basic implementation of our model,\n",
    "which may not yield the best performances.\n",
    "\n",
    "Some discussions are provided at the end to suggest further\n",
    "improvements.\n",
    ":::\n",
    "\n",
    "## Introduction\n",
    "\n",
    "When modeling radio propagations, RT is often used as a mean to evaluate of the trajectories\n",
    "that some radio waves can take to reach a given receiving antenna (RX), as emitted from a\n",
    "transmitting antenna (TX).\n",
    "\n",
    "With deterministic RT, also known as Point-to-Point (P2P) RT, we are interested\n",
    "in listing **all the possible physically valid ray paths** from TX to RX,\n",
    "that undergo up-to a fixed number of interaction, referred to as `order` in the code.\n",
    "\n",
    "After pre-processing the input scene, tracing those paths is usually a two-steps process:\n",
    "\n",
    "1. listing all possible path candidates between TX and RX;\n",
    "2. and for each path candidate, (a) tracing the physical path, and (b) removing paths that\n",
    "   are physically invalid (e.g., intersecting with any other object in the scene).\n",
    "\n",
    "In many applications, we can represent each path candidate as\n",
    "an ordered list of object indices :cite:`mpt-eucap2023,sionnart`,\n",
    "where each index indicates on which object the path should *interact* with.\n",
    "\n",
    "E.g., in the restricted context of specular reflections on flat walls,\n",
    "`path_candidate = [A, C, D]` indicates a path that undergoes 3 *reflections* between\n",
    "TX anx RX. The first one is on wall `A`, then the second is on wall `C`, and the\n",
    "third on wall `6`. Using this order sequence of wall indices, we can then easily\n",
    "construct the geometrical path of the ray, using, e.g., the image method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9311af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few importants imports to be able to run our code\n",
    "# 'type hint' related imports are only here for help documenting the code!\n",
    "\n",
    "from collections.abc import Iterator\n",
    "\n",
    "import equinox as eqx\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import optax\n",
    "from beartype import beartype as typechecker\n",
    "from jaxtyping import Array, Float, Int, PRNGKeyArray, jaxtyped\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "from differt2d.geometry import ImagePath, Point, Wall\n",
    "from differt2d.logic import is_true\n",
    "from differt2d.scene import Scene"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6fc26d-9540-4b37-8972-4e07a5b6de4b",
   "metadata": {},
   "source": [
    "## Motivations\n",
    "\n",
    "When performing P2P RT, enumerating all possible path candidates is usually the\n",
    "step that takes the most time, as the number of possible path candidates is in\n",
    "the order of $\\mathcal{O}(\\texttt{num_walls}^\\texttt{order})$. In large scenes,\n",
    "this number can become dramatically large. However, this number can be largely decreased\n",
    "if one knows the visibility matrix (or visibility tree, :cite:`visbilitytree`) of the scene,\n",
    "but such a matrix is not really easy too obtain (and can be also very costly\n",
    "to generate).\n",
    "\n",
    "However, not all path candidates will lead a valid geometrical ray paths.\n",
    "As such, **our model aims at directly sampling the path candidates that are\n",
    "very likely to produce a valid ray path**, in order to reduce the overall complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20035441-0369-4cbb-a4f8-fed8353f1385",
   "metadata": {},
   "source": [
    "### A basic scene with all valid ray paths\n",
    "\n",
    "To illustrate our motivations, we will first plot all the\n",
    "valid second-order (`order=2`) ray paths in a basic scene\n",
    "with one square obstacle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba065097-559e-49bf-ba45-e1b786af4f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "scene = Scene.square_scene_with_obstacle()\n",
    "scene.plot(ax)\n",
    "\n",
    "order = 2\n",
    "\n",
    "for _, _, path, _ in scene.all_valid_paths(order=order):\n",
    "    path.plot(ax)\n",
    "\n",
    "xlim = plt.xlim()\n",
    "ylim = plt.ylim()\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c561ca5-167e-4575-b9c5-e9baa4763ffc",
   "metadata": {},
   "source": [
    "### A basic scene with all valid and invalid ray paths\n",
    "\n",
    "In the above figure, we only showed *valid* ray paths.\n",
    "But what would happen if we also showed the *invalid* ones,\n",
    "i.e., the geometrical paths as generated by path candidates\n",
    "that **did not lead** to a valid path?\n",
    "\n",
    "This is what we show in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a065a44e-47ef-4fbe-a36e-dec46f6e8086",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "scene.plot(ax)\n",
    "\n",
    "num_valid_path_candidates = 0\n",
    "num_invalid_path_candidates = 0\n",
    "\n",
    "for _, _, valid, path, _ in scene.all_paths(min_order=order, max_order=order):\n",
    "    if is_true(valid):\n",
    "        num_valid_path_candidates += 1\n",
    "        (v,) = path.plot(ax)\n",
    "    else:\n",
    "        num_invalid_path_candidates += 1\n",
    "        (i,) = path.plot(ax, linestyle=\"--\", color=\"grey\", alpha=0.6)\n",
    "\n",
    "v.set_label(\"Valid paths\")\n",
    "i.set_label(\"Invalid paths\")\n",
    "\n",
    "print(\n",
    "    f\"Found {num_valid_path_candidates} valid path candidates, \"\n",
    "    f\"and {num_invalid_path_candidates} invalid path candidates,\\n\"\n",
    "    \"which translates to \"\n",
    "    f\"{100 * num_valid_path_candidates / (num_valid_path_candidates + num_invalid_path_candidates):.2f}% \"\n",
    "    \"of path candidates being valid.\"\n",
    ")\n",
    "\n",
    "plt.xlim(*xlim)\n",
    "plt.ylim(*ylim)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f7be40-dca4-4425-baea-6b38e608970e",
   "metadata": {},
   "source": [
    "As you can see, only **a small fraction** of the path candidates result\n",
    "in valid ray paths (orange solide lines).\n",
    "\n",
    "For sure, this fraction can change with respect with the input scenem\n",
    "but our model's hypothesis is that the number valid paths is usually\n",
    "much smaller than the total number of path candidates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd87d0bc-9d6e-4515-adfb-9469658405f4",
   "metadata": {},
   "source": [
    "## Model's goals\n",
    "\n",
    "As described above, our model should take **as input**:\n",
    "1. the TX coordinates;\n",
    "2. the RX coordinates;\n",
    "3. and an **unordered sequence** of **arbitrary many** objects.\n",
    "\n",
    "We restrict objects to be each represented by the same number of coordinates.\n",
    "\n",
    "E.g., all objects are 2D walls, each uniquely identified by $2\\times 2$ coordinates.\n",
    "\n",
    "The **output** should be a high-reward[^1] path candidate that undergoes\n",
    "`order` interaction with the scene's objects. To obtain more path candidates, we should simply query the\n",
    "model multiple times.\n",
    "\n",
    "[^1]: Here, the reward is high if the path candidate leads to a physically valid ray path."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13059f7-436e-4f52-a4fc-92d301feae90",
   "metadata": {},
   "source": [
    "### Note about reproducibility\n",
    "\n",
    "As we need randomness at various stages of this notebook,\n",
    "to generate the training data,\n",
    "to initialize the model's weights,\n",
    "and to sample path candidates with our model,\n",
    "we will first fix the random seed, the all the results below just\n",
    "be reproducible locally, on any computer.\n",
    "\n",
    "JAX is very different to NumPy, TensorFlow, and other array libraries, as it needs an explicit\n",
    "*Pseudo Random Generator Key* for each random data generation. Other libraries usually have it\n",
    "optional, and will work just fine by setting a `random.seed` at the very top of the project.\n",
    "\n",
    "Because JAX aims to produce reproducible, parallelizable, and vectorisable results, you\n",
    "**must** explicitly pass a PRNG key for each random numbers generation.\n",
    "\n",
    "The best practice is then to start from one unique *seed* key, and split it\n",
    "as many times as we need to generate random numbers. It is also best practice not\n",
    "to reuse a PRNG key for two different random numbers generations.\n",
    "\n",
    "For more details, read\n",
    "[JAX's tutorial on pseudorandom numbers](https://jax.readthedocs.io/en/latest/random-numbers.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fa0c3b-61dd-4da7-af37-584b51ebbc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(12345)  # 12345 is the 'random seed'\n",
    "key, key_example_scene = jax.random.split(key, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dfeb25-660d-4cf7-9675-7896234f9eeb",
   "metadata": {},
   "source": [
    "## Training data generation\n",
    "\n",
    "For this example, we limit ourselves to the study of specular reflection paths\n",
    "on straight walls. This is, **however**, not a limitation of our model.\n",
    "\n",
    "We generate data by applying random modifications on the very basic\n",
    "*square scene with obstacle*. The training data is simply a never ending\n",
    "iterator, which makes it very convenient of we want to increase the number\n",
    "of training steps.\n",
    "\n",
    "As every training sample is different, there is not real need to have both\n",
    "a training set and a test set. However, we will produce a validation set\n",
    "that will evaluate our model on a, hopefully representative, set of scenes.\n",
    "\n",
    "Also, the GFlowNet architecture has the advantage that we **do not** actually need\n",
    "the have a ground truth. Indeed, we simply need to have some *reward function*\n",
    "that evaluated some path candidate sampled by our model. Thus, this avoids\n",
    "us to enumerate all possible paths during training[^2].\n",
    "\n",
    "[^2]: As we will see in the [discussion](#discussion),\n",
    "    precomputing all possible paths during\n",
    "    training could help us skip scenes with no valid path, as it was observed\n",
    "    that it could improve the overall model's performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c60a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_samples(\n",
    "    min_ratio: float = 0.20,\n",
    "    max_ratio: float = 0.40,\n",
    "    min_num_walls: int = 4,\n",
    "    min_angle: float = -0.1 * jnp.pi,\n",
    "    max_angle: float = +0.1 * jnp.pi,\n",
    "    *,\n",
    "    key: PRNGKeyArray,\n",
    ") -> Iterator[Float[Array, \"2+num_walls*2 2\"]]:\n",
    "    \"\"\"\n",
    "    Returns a generator of random variants of :func:`Scene.square_scene_with_obstacle`.\n",
    "\n",
    "    The generation follows a three-steps process:\n",
    "\n",
    "    1. generate a ``square_scene_with_obstacle`` with a random scaling ratio;\n",
    "    2. sample a random number of walls from this scene;\n",
    "    3. and apply a random rotation around the scene's center for each wall.\n",
    "\n",
    "    :param min_ratio: The minimum scaling ratio of the inner square obstacle.\n",
    "    :param min_ratio: The maximum scaling ratio of the inner square obstacle.\n",
    "    :param min_num_walls: The minimum number of walls to sample (maximum is 8).\n",
    "    :param min_angle: The minimum rotation angle (random for each wall).\n",
    "    :param max_angle: The maximum rotation angle (random for each wall).\n",
    "    :param key: The random key to be used.\n",
    "    :return: An iterator over xys samples\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        key, key_ratio, key_tx_rx, key_num_walls, key_walls, key_angles = (\n",
    "            jax.random.split(key, 6)\n",
    "        )\n",
    "        # A random scaling is applied to the inner square\n",
    "        ratio = jax.random.uniform(key_ratio, minval=min_ratio, maxval=max_ratio)\n",
    "        # TX and RX are randomly sampled\n",
    "        points = jax.random.uniform(key_tx_rx, (2, 2))\n",
    "        # The walls are samples from the scene\n",
    "        scene = Scene.square_scene_with_obstacle(ratio=ratio)\n",
    "        center = scene.center()\n",
    "        indices = jnp.arange(len(scene.objects), dtype=jnp.int32)\n",
    "        # The number of walls is random\n",
    "        num_walls = jax.random.randint(\n",
    "            key_num_walls, (), minval=min_num_walls, maxval=len(scene.objects) + 1\n",
    "        )\n",
    "        # Walls are shuffled (to make sure deepset models is permutation invariant, but should not be needed)\n",
    "        wall_indices = jax.random.choice(\n",
    "            key_walls, indices, shape=(num_walls,), replace=False\n",
    "        )\n",
    "        # Each wall receives a random permutation around the center of the scene\n",
    "        angles = jax.random.uniform(\n",
    "            key_angles, shape=(num_walls,), minval=min_angle, maxval=max_angle\n",
    "        )\n",
    "        objects = [\n",
    "            scene.objects[wall_index].rotate(angle=angle, around=center)\n",
    "            for wall_index, angle in zip(wall_indices, angles)\n",
    "        ]\n",
    "\n",
    "        points = jnp.vstack([points, *[obj.xys for obj in objects]])\n",
    "\n",
    "        yield points\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def sample_2_scene(xys: Float[Array, \"2+num_walls*2 2\"]) -> Scene:\n",
    "    \"\"\"\n",
    "    Creates the scene corresponding to the given sample.\n",
    "\n",
    "    :param xys: The sample as returned by :func:`random_samples`.\n",
    "    :return: The corresponding scene.\n",
    "    \"\"\"\n",
    "    tx = Point(xy=xys[0, :])\n",
    "    rx = Point(xy=xys[1, :])\n",
    "\n",
    "    walls = xys[2:].reshape(-1, 2, 2)\n",
    "    walls = [Wall(xys=wall) for wall in walls]\n",
    "\n",
    "    return Scene(transmitters={\"tx\": tx}, receivers={\"rx\": rx}, objects=walls)\n",
    "\n",
    "\n",
    "samples = random_samples(key=key_example_scene)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6369c1-55bd-45ae-a5ef-16def56cd3f7",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eabdeb5-1f97-4745-b4db-bdb17205e7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell multiple times for different results!\n",
    "\n",
    "ax = plt.gca()\n",
    "scene = sample_2_scene(next(samples))\n",
    "scene.plot(ax)\n",
    "\n",
    "for _, _, path, _ in scene.all_valid_paths(order=order):\n",
    "    path.plot(ax)\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac336913-6a59-4eda-9ddc-621fc12b9a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, key_samples = jax.random.split(key, 2)\n",
    "\n",
    "# Let's filter out the cases with not valid paths,\n",
    "# because they are not interesting to learn from.\n",
    "\n",
    "num_val_samples = 100\n",
    "\n",
    "train_samples = random_samples(key=key_samples)\n",
    "\n",
    "val_samples = [next(train_samples) for i in range(num_val_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec513edd-a2d1-475e-91b7-81430bf7ab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "@jaxtyped(typechecker=typechecker)\n",
    "def reward(\n",
    "    pred_path_candidate: Int[Array, \"order\"],\n",
    "    scene: Scene,\n",
    ") -> Float[Array, \" \"]:\n",
    "    \"\"\"\n",
    "    Rewards a predicted path candidate depending on if it produces a valid path in the given scene.\n",
    "\n",
    "    :param pred_path_candidate: The predicted path candidate.\n",
    "    :param scene: The scene in which the path is traced.\n",
    "    :return: The (positive) reward.\n",
    "    \"\"\"\n",
    "    tx = scene.transmitters[\"tx\"]\n",
    "    rx = scene.receivers[\"rx\"]\n",
    "\n",
    "    # The following it a JIT-compatible variant of scene.get_interacting_objects\n",
    "    xys = jnp.stack(\n",
    "        [wall.xys for wall in scene.objects]\n",
    "    )  # Stack all walls into one array\n",
    "    interacting_walls = jnp.take(xys, pred_path_candidate, axis=0)\n",
    "    interacting_walls = [Wall(xys=wall) for wall in interacting_walls]\n",
    "\n",
    "    path = ImagePath.from_tx_objects_rx(tx, interacting_walls, rx)\n",
    "    valid = path.is_valid(scene.objects, pred_path_candidate, interacting_walls)\n",
    "\n",
    "    return valid.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e61089-be16-4561-bb5d-515a57a36976",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n",
    "scene.plot(ax)\n",
    "\n",
    "for _, _, valid, path, path_candidate in scene.all_paths(order=order):\n",
    "    if is_true(valid):\n",
    "        path.plot(ax)\n",
    "        s = \"valid  :\"\n",
    "    else:\n",
    "        s = \"invalid:\"\n",
    "\n",
    "    print(\n",
    "        f\"{s} path_candidate = {path_candidate.tolist()} has a reward of {reward(path_candidate, scene)}\"\n",
    "    )\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f48cbad-fbad-456a-aff0-8ed66c850d1b",
   "metadata": {},
   "source": [
    "## Model definition\n",
    "\n",
    "Our model follows the architecture of GFlowNet models: the goal is to **learn how sample path candidates**\n",
    "(here, the final state of the flowchart) such that their sampling rate is proportional to their corresponding\n",
    "reward.\n",
    "\n",
    "A path candidate is simply a list of wall indices, e.g., `[A, C]`[^2]. A path candidate under\n",
    "construction (i.e., not yet completed), is represented with `X` for undecided states.\n",
    "\n",
    "[^2]: Numeric indices are replaced here with letters, to make it simpler. In practice, walls\n",
    "    are identified based on a zero-based array indexing.\n",
    "\n",
    "E.g., `path_candidate = [A, X]` indicates a path with 2 interactions, where the first\n",
    "is already defined (i.e., wall `A`).\n",
    "\n",
    "For each path candidate, either incomplete or complete, there is a unique state $s$ representing it. In the code, states\n",
    "are obtained by encoding the corresponding path candidate using one-hot encoding.\n",
    "\n",
    "E.g., the complete `path_candidate = [A, C]` is represented by the following state\n",
    "(assuming 3 objects in the scene):\n",
    "\n",
    "```python\n",
    "state = [\n",
    "  [1, 0],  # Wall A\n",
    "  [0, 0],  # Wall B\n",
    "  [0, 0],  # Wall C\n",
    "]\n",
    "```\n",
    "\n",
    "While the incomplete `path_candidate = [A, X]` is represented by:\n",
    "\n",
    "```python\n",
    "state = [\n",
    "  [1, 0],  # Wall A\n",
    "  [0, 0],  # Wall B\n",
    "  [0, 1],  # Wall C\n",
    "]\n",
    "```\n",
    "\n",
    "The last column being all zeros refers to the `X`.\n",
    "\n",
    "Below, the diagram of all possible states is shown. As interacting with the same\n",
    "object twice in a row is **physically unsound**, this state is **unreachable** (dotted lines).\n",
    "To account for that in the model, the flow is stopped to prevent reaching those states.\n",
    "\n",
    "```{mermaid}\n",
    ":align: center\n",
    ":caption: Flowchart of all possible states for a 2-order path candidates in a scene with 3 walls.\n",
    "\n",
    "flowchart TD\n",
    "    ?(??) -->|\"F(??, A?)\"| A(A?)\n",
    "    ? -->|\"F(??, A?)\"| B(B?)\n",
    "    ? -->|\"F(??, A?)\"| C(C?)\n",
    "\n",
    "    A -.-x|\"F(A?, AA)\"| AA(AA)\n",
    "    A -->|\"F(A?, AB)\"| AB(AB)\n",
    "    A -->|\"F(A?, AC)\"| AC(AC)\n",
    "\n",
    "    B -->|\"F(B?, BA)\"| BA(BA)\n",
    "    B -.-x|\"F(B?, BB)\"| BB(BB)\n",
    "    B -->|\"F(B?, BC)\"| BC(BC)\n",
    "\n",
    "    C -->|\"F(C?, CA)\"| CA(CA)\n",
    "    C -->|\"F(C?, CB)\"| CB(CB)\n",
    "    C -.-x|\"F(C?, CC)\"| CC(CC)\n",
    "```\n",
    "\n",
    "The construction of any path candidate start at the `??` state.\n",
    "Then, the next state is chosen randomly, accordingly to the flow model,\n",
    "see next the [#Loss function definition] for more details.\n",
    "For second order path candidates, this step is **repeated twice**.\n",
    "\n",
    "The next flowchart indicate the construction of `path_candidate = [A, X]`.\n",
    "\n",
    "```{mermaid}\n",
    ":align: center\n",
    ":caption: Flowchart of with edge leading to the construction of `[A, X]` highlighted.\n",
    "\n",
    "flowchart TD\n",
    "    ?(??) -->|\"F(??, A?)\"| A(A?)\n",
    "    ? -->|\"F(??, A?)\"| B(B?)\n",
    "    ? -->|\"F(??, A?)\"| C(C?)\n",
    "\n",
    "    A -.-x|\"F(A?, AA)\"| AA(AA)\n",
    "    A -->|\"F(A?, AB)\"| AB(AB)\n",
    "    A -->|\"F(A?, AC)\"| AC(AC)\n",
    "\n",
    "    B -->|\"F(B?, BA)\"| BA(BA)\n",
    "    B -.-x|\"F(B?, BB)\"| BB(BB)\n",
    "    B -->|\"F(B?, BC)\"| BC(BC)\n",
    "\n",
    "    C -->|\"F(C?, CA)\"| CA(CA)\n",
    "    C -->|\"F(C?, CB)\"| CB(CB)\n",
    "    C -.-x|\"F(C?, CC)\"| CC(CC)\n",
    "    \n",
    "    linkStyle 0 stroke:#ff3,stroke-width:4px,background-color:lime;\n",
    "```\n",
    "\n",
    "Finally, the complete path candidate, here `[A, C]` is reached after a second call to our model.\n",
    "\n",
    "```{mermaid}\n",
    ":align: center\n",
    ":caption: Flowchart of with edges leading to the construction of `[A, C]` highlighted.\n",
    "\n",
    "flowchart TD\n",
    "    ?(??) -->|\"F(??, A?)\"| A(A?)\n",
    "    ? -->|\"F(??, A?)\"| B(B?)\n",
    "    ? -->|\"F(??, A?)\"| C(C?)\n",
    "\n",
    "    A -.-x|\"F(A?, AA)\"| AA(AA)\n",
    "    A -->|\"F(A?, AB)\"| AB(AB)\n",
    "    A -->|\"F(A?, AC)\"| AC(AC)\n",
    "\n",
    "    B -->|\"F(B?, BA)\"| BA(BA)\n",
    "    B -.-x|\"F(B?, BB)\"| BB(BB)\n",
    "    B -->|\"F(B?, BC)\"| BC(BC)\n",
    "\n",
    "    C -->|\"F(C?, CA)\"| CA(CA)\n",
    "    C -->|\"F(C?, CB)\"| CB(CB)\n",
    "    C -.-x|\"F(C?, CC)\"| CC(CC)\n",
    "    \n",
    "    linkStyle 0 stroke:#ff3,stroke-width:4px,background-color:lime;\n",
    "    linkStyle 5 stroke:#ff3,stroke-width:4px,background-color:lime;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c985f39b-501f-4c4a-abdf-474c1568ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowModel(eqx.Module):\n",
    "    \"\"\"The flow model that returns flows between two states.\"\"\"\n",
    "\n",
    "    # Layers\n",
    "    wall_2_embeddings: eqx.nn.MLP\n",
    "    \"\"\"MLP that is applied to each wall in parallel and returns the corresponding embeddings.\"\"\"\n",
    "    embeddings_2_flow: eqx.nn.MLP\n",
    "    \"\"\"MLP that maps each possible choice to some positive flow.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        # Hyperparameters\n",
    "        num_embeddings: int = 100,\n",
    "        *,\n",
    "        key: PRNGKeyArray,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Constructs a GFlowNet model.\n",
    "\n",
    "        :param num_embeddings: The size of the vector that will represent each wall.\n",
    "        :param key: The random key to be used.\n",
    "        \"\"\"\n",
    "        key1, key2 = jax.random.split(key, 2)\n",
    "\n",
    "        # Layers\n",
    "        self.wall_2_embeddings = eqx.nn.MLP(\n",
    "            in_size=4,\n",
    "            out_size=num_embeddings,\n",
    "            width_size=500,\n",
    "            depth=3,\n",
    "            key=key1,\n",
    "        )\n",
    "        self.embeddings_2_flow = eqx.nn.MLP(\n",
    "            in_size=4\n",
    "            + 2 * num_embeddings\n",
    "            + 4,  # [tx_rx, state_embeddings, scene_embeddings, wall[i]]\n",
    "            out_size=\"scalar\",\n",
    "            width_size=500,\n",
    "            depth=3,\n",
    "            final_activation=jnp.exp,  # Positive flow only\n",
    "            key=key2,\n",
    "        )\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    @jaxtyped(typechecker=typechecker)\n",
    "    def __call__(\n",
    "        self,\n",
    "        state: Float[Array, \"num_walls order\"],\n",
    "        wall_index: Int[Array, \" \"],\n",
    "        xys: Float[Array, \"2+num_walls*2 2\"],\n",
    "    ) -> Float[Array, \"num_walls\"]:\n",
    "        \"\"\"\n",
    "        Calls this model in order to generate a new flow from a given state,\n",
    "        the last selected wall index, and some input scene.\n",
    "\n",
    "        :param state: The current state, a one-hot encoding of the path candidate\n",
    "            in construction. Only one element per column can be non-zero.\n",
    "        :param wall_index: The index of the last wall that was selected. A negative index\n",
    "            indicates that no wall was previously selected.\n",
    "        :param xys: The array of xy-coordinates, as returned by\n",
    "            :func:`random_samples`.\n",
    "        :return: The array of flows, one per wall in the scene.\n",
    "        \"\"\"\n",
    "        assert (\n",
    "            xys.shape[0] >= 4\n",
    "        ), \"Scene must at least have two points, tx and rx, and one wall!\"\n",
    "\n",
    "        num_walls, order = state.shape\n",
    "\n",
    "        # Data normalization\n",
    "        eps = 1e-5\n",
    "        mean = jnp.mean(xys, axis=0, keepdims=True)\n",
    "        std = jnp.std(xys, axis=0, keepdims=True)\n",
    "\n",
    "        xys = (xys - mean) / (std + eps)\n",
    "\n",
    "        tx_rx = xys[:2, :].reshape(4)\n",
    "        walls = xys[2:, :].reshape(num_walls, 4)\n",
    "\n",
    "        # [num_walls 4]\n",
    "        # note: this input we be the same for every wall\n",
    "        tx_rx = jnp.tile(tx_rx, (num_walls, 1))\n",
    "\n",
    "        # [num_walls num_embeddings]\n",
    "        # note: each wall is mapped to a vector of embeddings\n",
    "        walls_embeddings = jax.vmap(self.wall_2_embeddings)(walls)\n",
    "\n",
    "        # [num_embeddings]\n",
    "        # note: the scene is the sum of all embeddings\n",
    "        scene_embeddings = jnp.sum(walls_embeddings, axis=0)\n",
    "\n",
    "        # [num_walls num_embeddings]\n",
    "        # note: this input we be the same for every wall\n",
    "        scene_embeddings = jnp.tile(scene_embeddings, (num_walls, 1))\n",
    "\n",
    "        # [order]\n",
    "        # note: fill_value=num_walls is important as we need to generate 'out of bounds'\n",
    "        #       indices for missing values (only current_order <= order are non zero)\n",
    "        wall_indices, _ = jnp.nonzero(state, size=order, fill_value=num_walls)\n",
    "\n",
    "        # [order num_embeddings]\n",
    "        # note: we tell JAX to replace 'out of bounds' indices with zeros,\n",
    "        #       as this will have no impact on the sum (see next step)\n",
    "        state_embeddings = jnp.take(\n",
    "            walls_embeddings, wall_indices, axis=0, fill_value=0\n",
    "        )\n",
    "\n",
    "        # [num_embeddings]\n",
    "        # note: this contains information about the walls we already visited,\n",
    "        #       as a sum of corresponding embeddings (one wall can appear multiple times)\n",
    "        state_embeddings = jnp.sum(state_embeddings, axis=0)\n",
    "\n",
    "        # [num_walls num_embeddings]\n",
    "        # note: this input we be the same for every wall\n",
    "        state_embeddings = jnp.tile(state_embeddings, (num_walls, 1))\n",
    "\n",
    "        # [num_walls]\n",
    "        # note: the input (per wall) looks as follows\n",
    "        #       # [tx_rx, state_embeddings, scene_embeddings, wall[i]]\n",
    "        flow = jax.vmap(self.embeddings_2_flow)(\n",
    "            jnp.hstack((tx_rx, state_embeddings, scene_embeddings, walls))\n",
    "        )\n",
    "\n",
    "        # Set flow[wall_index] to zero to prevent consecutive duplicate indices\n",
    "        # A flow of zero means that there is a zero probability to pick\n",
    "        # walls[wall_index] for the next state.\n",
    "        flow = flow.at[wall_index].set(0.0)  # out of bounds indices are ignored\n",
    "\n",
    "        return flow\n",
    "\n",
    "\n",
    "class Model(eqx.Module):\n",
    "    \"\"\"The generative model that samples a path candidate from flows.\"\"\"\n",
    "\n",
    "    flow: FlowModel\n",
    "    \"\"\"The learnable flow model.\"\"\"\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def __call__(\n",
    "        self,\n",
    "        xys: Float[Array, \"2+num_walls*2 2\"],\n",
    "        *,\n",
    "        order: int,\n",
    "        key: PRNGKeyArray,\n",
    "    ) -> Int[Array, \"{order}\"]:\n",
    "        \"\"\"\n",
    "        Calls this model to generate a path candidate of the given order.\n",
    "\n",
    "        :param xys: The array of xy-coordinates, as returned by\n",
    "            :func:`random_samples`.\n",
    "        :param order: The order of the path candidate.\n",
    "        :param key: The random key to be used.\n",
    "        :return: A path candidate.\n",
    "        \"\"\"\n",
    "        # See loss function for detailed comments\n",
    "        num_walls = (xys.shape[0] - 2) // 2\n",
    "\n",
    "        ScanR = Int[Array, \" \"]\n",
    "        ScanC = tuple[\n",
    "            Float[Array, \" num_walls\"],\n",
    "            Float[Array, \"num_walls order\"],\n",
    "        ]\n",
    "\n",
    "        @jaxtyped(typechecker=typechecker)\n",
    "        def scan_fn(\n",
    "            carry: ScanC, key_and_current_order: tuple[PRNGKeyArray, Int[Array, \" \"]]\n",
    "        ) -> tuple[ScanC, ScanR]:\n",
    "            parent_edge_flow_prediction, state = carry\n",
    "            key, current_order = key_and_current_order\n",
    "\n",
    "            p = parent_edge_flow_prediction / jnp.sum(parent_edge_flow_prediction)\n",
    "\n",
    "            wall_index = jax.random.categorical(key=key, logits=jnp.log(p))\n",
    "\n",
    "            state = state.at[wall_index, current_order].set(1.0)\n",
    "\n",
    "            edge_flow_prediction = self.flow(state, wall_index, xys)\n",
    "\n",
    "            return (edge_flow_prediction, state), wall_index\n",
    "\n",
    "        wall_index = jnp.array(num_walls)\n",
    "        state = jnp.zeros((num_walls, order))\n",
    "        parent_edge_flow_prediction = self.flow(state, wall_index, xys)\n",
    "        init = parent_edge_flow_prediction, state\n",
    "        _, pred_path_candidate = jax.lax.scan(\n",
    "            scan_fn,\n",
    "            init,\n",
    "            xs=(jax.random.split(key, order), jnp.arange(order)),\n",
    "        )\n",
    "\n",
    "        return pred_path_candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7470ffd2-f9c3-4e68-a535-c3848af1a60f",
   "metadata": {},
   "source": [
    "## Loss function definition\n",
    "\n",
    "A central property of GFlowNet models that, after successful training, the model should samples terminal states, i.e.,\n",
    "complete path candidates, with a probability $p$, that is proportial to their corresponding reward, $R$.\n",
    "\n",
    "In other words, $$p(\\mathcal{P}) \\propto R(\\mathcal{P}),$$\n",
    "\n",
    "where $\\mathcal{P}$ is one possible path candidate, \n",
    "\n",
    "To reach this property, the model must have the following properties:\n",
    "\n",
    "1. each edge must be assigned a positive flow, $F(s,s') > 0$, where $s$ is the parent state and $s'$ is the child state;\n",
    "2. the flow consistency must be ensured:\n",
    "   $$\\forall s', \\sum_{s: (s,s')\\in\\mathcal{E}} F(s,s') = R(s') + \\sum_{s'':(s',s'')\\in\\mathcal{E}} F(s',s''),$$\n",
    "   that is, the sum of output flows, $F(s',s'')$, must be equal to the input flow, $F(s,s')$, minus the reward;\n",
    "3. and $$p(s'|s) = \\frac{F(s,s')}{\\sum_{s''}F(s,s'')},$$\n",
    "   that is, the probability of choosing state $s'$ from state $s$.\n",
    "\n",
    "Note that all states, except the terminal states, have a zero reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be7b365-8559-4413-8485-a6126cebee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jaxtyped(typechecker=None)\n",
    "def loss(\n",
    "    model: FlowModel,\n",
    "    xys: Float[Array, \"2+num_walls*2 2\"],\n",
    "    batch_size: int = 10,\n",
    "    plot: bool = False,\n",
    "    *,\n",
    "    order: int,\n",
    "    key: PRNGKeyArray,\n",
    ") -> Float[Array, \" \"]:\n",
    "    \"\"\"\n",
    "    Compute the loss of the model on a specific input scene.\n",
    "\n",
    "    The loss is accumulated over the generation of 'batch_size' path candidates.\n",
    "    \"\"\"\n",
    "    num_walls = (xys.shape[0] - 2) // 2\n",
    "    scene = sample_2_scene(xys)\n",
    "\n",
    "    ScanR = Int[Array, \" \"]\n",
    "    ScanC = tuple[\n",
    "        Float[Array, \" \"],\n",
    "        Float[Array, \" num_walls\"],\n",
    "        Float[Array, \"num_walls order\"],\n",
    "    ]\n",
    "\n",
    "    @jaxtyped(typechecker=typechecker)\n",
    "    def scan_fn(\n",
    "        carry: ScanC, key_and_current_order: tuple[PRNGKeyArray, Int[Array, \" \"]]\n",
    "    ) -> tuple[ScanC, ScanR]:\n",
    "        # We carry, for the currently generated path candidate:\n",
    "        # - the flow mismatch (parent edges flow - current flow)\n",
    "        # - the parent edge flow (only one parent leads to the current choice)\n",
    "        # - the state (path candidate using one-hot encoding)\n",
    "        flow_mismatch, parent_edge_flow_prediction, state = carry\n",
    "        key, current_order = key_and_current_order\n",
    "\n",
    "        # Turn positive flow into normalized probability in [0, 1]\n",
    "        p = parent_edge_flow_prediction / jnp.sum(parent_edge_flow_prediction)\n",
    "\n",
    "        wall_index = jax.random.categorical(\n",
    "            key=key, logits=jnp.log(p)\n",
    "        )  # The wall to choose\n",
    "\n",
    "        # Indicate we have chosen walls[wall_index] as a candidate at 'current_order'\n",
    "        state = state.at[wall_index, current_order].set(1.0)\n",
    "\n",
    "        edge_flow_prediction = model(state, wall_index, xys)\n",
    "\n",
    "        pred_path_candidate, _ = jnp.nonzero(state, size=order, fill_value=num_walls)\n",
    "\n",
    "        flow_mismatch += jnp.where(\n",
    "            current_order == order - 1,  # Check whether we reached final state\n",
    "            (  # Reached last state so (next) edge_flow_prediction is ignored\n",
    "                parent_edge_flow_prediction[\n",
    "                    wall_index\n",
    "                ]  # Each state s' has only one possible parent state s\n",
    "                - reward(pred_path_candidate, scene)\n",
    "            )\n",
    "            ** 2,\n",
    "            (  # Didn't reach last state so no reward\n",
    "                parent_edge_flow_prediction[\n",
    "                    wall_index\n",
    "                ]  # Each state s' has only one possible parent state s\n",
    "                - jnp.sum(edge_flow_prediction)\n",
    "            )\n",
    "            ** 2,\n",
    "        )\n",
    "\n",
    "        return (flow_mismatch, edge_flow_prediction, state), wall_index\n",
    "\n",
    "    BatchC = Float[Array, \" \"]\n",
    "    BatchR = Int[Array, \" order\"]\n",
    "\n",
    "    @jaxtyped(typechecker=typechecker)\n",
    "    def batch_fn(batch_loss: BatchC, key: PRNGKeyArray) -> tuple[BatchC, BatchR]:\n",
    "        flow_mismatch = jnp.array(0.0)  # We mismatch for the current path_candidate\n",
    "        wall_index = jnp.array(\n",
    "            num_walls\n",
    "        )  # We didn't select any wall yet: out of bounds index\n",
    "        state = jnp.zeros(\n",
    "            (num_walls, order)\n",
    "        )  # Same, but represented in one-hot encoding\n",
    "        parent_edge_flow_prediction = model(\n",
    "            state, wall_index, xys\n",
    "        )  # Initial state's flow\n",
    "        init = flow_mismatch, parent_edge_flow_prediction, state\n",
    "        (flow_mismatch, *_), pred_path_candidate = jax.lax.scan(\n",
    "            scan_fn,\n",
    "            init,\n",
    "            xs=(jax.random.split(key, order), jnp.arange(order)),\n",
    "        )\n",
    "\n",
    "        return batch_loss + flow_mismatch, pred_path_candidate\n",
    "\n",
    "    batch_loss = jnp.array(0.0)\n",
    "    batch_loss, pred_path_candidates = jax.lax.scan(\n",
    "        batch_fn, batch_loss, xs=jax.random.split(key, batch_size)\n",
    "    )\n",
    "\n",
    "    if plot:\n",
    "        ax = plt.gca()\n",
    "        scene.plot(ax)\n",
    "        ax.set_xlim(-0.1, 1.1)\n",
    "        ax.set_ylim(-0.1, 1.1)\n",
    "        tx = scene.transmitters[\"tx\"]\n",
    "        rx = scene.receivers[\"rx\"]\n",
    "\n",
    "        gt = None\n",
    "        for _, _, path, _ in scene.all_valid_paths(order=order):\n",
    "            (gt,) = path.plot(ax, color=\"orange\")\n",
    "\n",
    "        if gt is not None:\n",
    "            gt.set_label(\"Ground Truth\")\n",
    "\n",
    "        n_unique = 0\n",
    "        pr = None\n",
    "        for pred_path_candidate in jnp.unique(pred_path_candidates, axis=0):\n",
    "            n_unique += 1\n",
    "            objects = [scene.objects[i] for i in pred_path_candidate]\n",
    "            (pr,) = ImagePath.from_tx_objects_rx(tx, objects, rx).plot(\n",
    "                ax, linestyle=\"--\", alpha=0.5, color=\"red\"\n",
    "            )\n",
    "\n",
    "        if pr is not None:\n",
    "            pr.set_label(\"Prediction\")\n",
    "\n",
    "        plt.title(f\"Generated {batch_size} path cand. (of which {n_unique} are unique)\")\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"x\")\n",
    "        plt.ylabel(\"y\")\n",
    "        plt.show()\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf67f8a-b55a-4449-bdce-6a1fd6bf25fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, key_model = jax.random.split(key, 2)\n",
    "untrained_model = FlowModel(key=key_model)\n",
    "optim = optax.adam(learning_rate=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7cb03a-b637-4fc5-bd98-129c48844f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell multiple times for different results!\n",
    "\n",
    "key, key_loss_untrained = jax.random.split(key, 2)\n",
    "loss(\n",
    "    untrained_model, next(train_samples), plot=True, order=1, key=key_loss_untrained\n",
    ")  # Untrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737b698a-6b75-4d5e-9f5c-e640efedb8d8",
   "metadata": {},
   "source": [
    "## Training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930a3ef7-345b-4e47-993e-64944701a597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: FlowModel,\n",
    "    train_samples: Iterator[Float[Array, \"2+num_walls*2 2\"]],\n",
    "    val_samples: list[Float[Array, \"2+num_walls*2 2\"]],\n",
    "    optim: optax.GradientTransformation,\n",
    "    steps: int = 10,  # 30_000,\n",
    "    print_every: int = 100,\n",
    "    *,\n",
    "    order: int,\n",
    "    key: PRNGKeyArray,\n",
    ") -> tuple[FlowModel, Float[Array, \"{steps}//{print_every}\"]]:\n",
    "    \"\"\"\n",
    "    Trains a flow model on a sequence of training samples and returns the averaged loss over validation samples.\n",
    "\n",
    "    :param model: The model to train.\n",
    "    :param train_samples: The training samples.\n",
    "    :param val_samples: The validation samples.\n",
    "    :param optim: The optimizer to use.\n",
    "    :param steps: The number of optimization steps.\n",
    "    :param print_every: The frequency at which the average loss is computed.\n",
    "    :param order: The order of the paths to be trained on.\n",
    "    :param key: The random key to be used.\n",
    "    \"\"\"\n",
    "    opt_state = optim.init(eqx.filter(model, eqx.is_array))\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def make_step(\n",
    "        model: FlowModel,\n",
    "        opt_state: optax.OptState,\n",
    "        xys: Float[Array, \"2+num_walls*2 2\"],\n",
    "        *,\n",
    "        order: int,\n",
    "        key: PRNGKeyArray,\n",
    "    ):\n",
    "        loss_value, grads = eqx.filter_value_and_grad(loss)(\n",
    "            model, xys, order=order, key=key\n",
    "        )\n",
    "        updates, opt_state = optim.update(grads, opt_state, model)\n",
    "        model = eqx.apply_updates(model, updates)\n",
    "        return model, opt_state, loss_value\n",
    "\n",
    "    losses = []\n",
    "    jitted_loss = eqx.filter_jit(loss)\n",
    "\n",
    "    with trange(steps, desc=\"\", unit=\" steps\", leave=True) as bar:\n",
    "        for (\n",
    "            step,\n",
    "            xys_train,\n",
    "        ) in zip(bar, train_samples):\n",
    "            key, key_step = jax.random.split(key, 2)\n",
    "\n",
    "            model, opt_state, train_loss = make_step(\n",
    "                model, opt_state, xys_train, order=order, key=key_step\n",
    "            )\n",
    "\n",
    "            if (step % print_every) == 0 or (step == steps - 1):\n",
    "                # Only update the training 'bar' every few steps\n",
    "                val_loss = 0.0\n",
    "                for xys_val in val_samples:\n",
    "                    key, key_val = jax.random.split(key, 2)\n",
    "                    val_loss += jitted_loss(model, xys_val, order=order, key=key_val)\n",
    "\n",
    "                val_loss /= len(val_samples)\n",
    "\n",
    "                losses.append(val_loss)\n",
    "\n",
    "                bar.set_description(\n",
    "                    f\"train_loss = {float(train_loss):.1f}, val_loss = {float(val_loss):.1f}\"\n",
    "                )\n",
    "\n",
    "    return model, jnp.array(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c04eb13-9336-49d5-aecb-8588b265f13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, key_train = jax.random.split(key, 2)\n",
    "\n",
    "trained_model_order_1, losses = train(\n",
    "    untrained_model, train_samples, val_samples, optim, order=1, key=key_train\n",
    ")\n",
    "\n",
    "plt.semilogy(losses)\n",
    "plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b89681-9349-4c72-902d-a52894e0e639",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, key_loss_trained = jax.random.split(key, 2)\n",
    "\n",
    "loss(\n",
    "    trained_model_order_1, next(train_samples), plot=True, order=1, key=key_loss_trained\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ecfc03-a8a9-4265-a440-5edf7b25bdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, key_train = jax.random.split(key, 2)\n",
    "trained_model_order_2, losses = train(\n",
    "    untrained_model, train_samples, val_samples, optim, order=2, key=key_train\n",
    ")\n",
    "\n",
    "plt.semilogy(losses)\n",
    "plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef52320-0e1d-4463-8eb4-737ca97e3bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell multiple times for different results!\n",
    "\n",
    "key, key_loss_trained = jax.random.split(key, 2)\n",
    "\n",
    "loss(\n",
    "    trained_model_order_2, next(train_samples), plot=True, order=2, key=key_loss_trained\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe511be-0255-42b6-ab64-7f8c604699fe",
   "metadata": {},
   "source": [
    "## Inference phase\n",
    "\n",
    "Once the model has been trained, we can instantiate a complete Machine Learning\n",
    "model to sample path candidates. In itself, the `Model` class is just a plan\n",
    "wrapper around the trained `FlowModel` instance, that will call\n",
    "it repeatedly to generate path candidates of a given size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b806ea50-1a7f-4f79-87a1-8934baeed9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    flow=eqx.nn.inference_mode(\n",
    "        trained_model_order_2\n",
    "    )  # Here, this is a no-op (just copies the model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ef95aa-37cc-48a4-b098-33a3c202c082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell multiple times for different results!\n",
    "\n",
    "key, key_inference = jax.random.split(key, 2)\n",
    "\n",
    "model(next(train_samples), order=2, key=key_inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f0fa52-4b4d-44a5-8242-4441b01aded8",
   "metadata": {},
   "source": [
    "=(discussion)\n",
    "## Discussion\n",
    "\n",
    "The above results show that the learning process isn...\n",
    "\n",
    "\n",
    "A few future .. are envi:\n",
    "- removing from the training data the scenes that **do not any any valid path**:\n",
    "  they are not actually very interesting for our problem, and may have a detrimental impact on the\n",
    "  learning process as the model will not receive any reward.\n",
    "- to enhance generalization, we also could think of accumulating the loss on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc66ffb9-5d90-4094-a32c-9e329b70c195",
   "metadata": {},
   "source": [
    "## Appendix - Training on curated scenes\n",
    "\n",
    "As suggested in the [discussion](#discussion), for show how the training on a curated training\n",
    "dataset, with some scenes removed, can help improving the learning process.\n",
    "\n",
    "Here, the `filter_xys` function just returns `True` if the scene\n",
    "will at least contain one valid ray path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af102125-5fa4-485b-af4a-a63134d1e37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_xys(xys: Float[Array, \"2+num_walls*2 2\"]) -> bool:\n",
    "    scene = sample_2_scene(xys)\n",
    "\n",
    "    for _ in scene.all_valid_paths(order=order):\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "curated_train_samples = filter(filter_xys, train_samples)\n",
    "curated_val_samples = [next(curated_train_samples) for i in range(num_val_samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acf9910-b036-438a-b001-9efcd2874683",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, key_curated_train = jax.random.split(key, 2)\n",
    "trained_curated_model, losses = train(\n",
    "    untrained_model,\n",
    "    curated_train_samples,\n",
    "    curated_val_samples,\n",
    "    optim,\n",
    "    order=1,\n",
    "    key=key_curated_train,\n",
    ")\n",
    "\n",
    "plt.semilogy(losses)\n",
    "plt.xlabel(\"steps\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdf60bd-335d-4f6f-a820-42cca3b0887b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
